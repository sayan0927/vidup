var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
var __async = (__this, __arguments, generator) => {
  return new Promise((resolve, reject) => {
    var fulfilled = (value) => {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    };
    var rejected = (value) => {
      try {
        step(generator.throw(value));
      } catch (e) {
        reject(e);
      }
    };
    var step = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
    step((generator = generator.apply(__this, __arguments)).next());
  });
};

// src/components/index.browser.ts
var index_browser_exports = {};
__export(index_browser_exports, {
  AACDepay: () => AACDepay,
  BasicDepay: () => BasicDepay,
  CanvasSink: () => CanvasSink,
  H264Depay: () => H264Depay,
  HttpSource: () => HttpSource,
  Inspector: () => Inspector,
  JPEGDepay: () => JPEGDepay,
  MessageType: () => MessageType,
  Mp4Capture: () => Mp4Capture,
  Mp4Muxer: () => Mp4Muxer,
  MseSink: () => MseSink,
  ONVIFDepay: () => ONVIFDepay,
  RTSPResponseError: () => RTSPResponseError,
  RTSP_METHOD: () => RTSP_METHOD,
  RtspParser: () => RtspParser,
  RtspSession: () => RtspSession,
  Sink: () => Sink,
  Source: () => Source,
  Tube: () => Tube,
  WSSource: () => WSSource,
  createTransform: () => createTransform
});

// src/components/component.ts
import { PassThrough, Readable as Readable2, Writable as Writable2 } from "stream";

// src/components/helpers/stream-factory.ts
import { Readable, Transform, Writable } from "stream";
var StreamFactory = class {
  /**
   * Creates a writable stream that sends all messages written to the stream
   * to a callback function and then considers it written.
   * @param fn  The callback to be invoked on the message
   */
  static consumer(fn = () => {
  }) {
    return new Writable({
      objectMode: true,
      write(msg, _encoding, callback) {
        fn(msg);
        callback();
      }
    });
  }
  static peeker(fn) {
    if (typeof fn !== "function") {
      throw new Error("you must supply a function");
    }
    return new Transform({
      objectMode: true,
      transform(msg, _encoding, callback) {
        fn(msg);
        callback(void 0, msg);
      }
    });
  }
  /**
   * Creates a readable stream that sends a message for each element of an array.
   * @param arr  The array with elements to be turned into a stream.
   */
  static producer(messages) {
    let counter = 0;
    return new Readable({
      objectMode: true,
      read() {
        if (messages !== void 0) {
          if (counter < messages.length) {
            this.push(messages[counter++]);
          } else {
            this.push(null);
          }
        }
      }
    });
  }
  static recorder(type, fileStream) {
    return new Transform({
      objectMode: true,
      transform(msg, encoding, callback) {
        const timestamp2 = Date.now();
        const message = Object.assign({}, msg, {
          data: msg.data.toString("base64")
        });
        fileStream.write(JSON.stringify({ type, timestamp: timestamp2, message }, null, 2));
        fileStream.write(",\n");
        callback(void 0, msg);
      }
    });
  }
  /**
   * Yield binary messages from JSON packet array until depleted.
   * @return {Generator} Returns a JSON packet iterator.
   */
  static replayer(packets) {
    let packetCounter = 0;
    let lastTimestamp = packets[0].timestamp;
    return new Readable({
      objectMode: true,
      read() {
        const packet = packets[packetCounter++];
        if (packet) {
          const { type, timestamp: timestamp2, message } = packet;
          const delay = timestamp2 - lastTimestamp;
          lastTimestamp = timestamp2;
          if (message) {
            const data = message.data ? Buffer.from(message.data, "base64") : Buffer.alloc(0);
            const msg = Object.assign({}, message, { data });
            this.push({ type, delay, msg });
          } else {
            this.push({ type, delay, msg: null });
          }
        } else {
          this.push(null);
        }
      }
    });
  }
};

// src/components/component.ts
var AbstractComponent = class {
  constructor() {
    __publicField(this, "_incomingErrorHandler");
    __publicField(this, "_outgoingErrorHandler");
  }
};
var Source = class _Source extends AbstractComponent {
  constructor(incoming = new Readable2({ objectMode: true }), outgoing = new Writable2({ objectMode: true })) {
    super();
    __publicField(this, "incoming");
    __publicField(this, "outgoing");
    __publicField(this, "next");
    __publicField(this, "prev");
    this.incoming = incoming;
    this.outgoing = outgoing;
    this.next = null;
    this.prev = null;
  }
  /**
   * Set up a source component that has a message list as data source.
   *
   * @param messages - List of objects (with data property) to emit on the
   * incoming stream
   */
  static fromMessages(messages) {
    const component = new _Source(
      StreamFactory.producer(messages),
      StreamFactory.consumer()
    );
    return component;
  }
  /**
   * Attach another component so the the 'down' stream flows into the
   * next component 'down' stream and the 'up' stream of the other component
   * flows into the 'up' stream of this component. This is what establishes the
   * meaning of 'up' and 'down'.
   * @param  next - The component to connect.
   * @return A reference to the connected component.
   *
   *      -------------- pipe --------------
   *  <-  |  outgoing  |  <-  |  outgoing  | <-
   *      |    this    |      |    next    |
   *  ->  |  incoming  |  ->  |  incoming  | ->
   *      -------------- pipe --------------
   */
  connect(next) {
    if (next === null) {
      return this;
    } else if (this.next !== null || next.prev !== null) {
      throw new Error("connection failed: component(s) already connected");
    }
    if (!this.incoming.readable || !this.outgoing.writable) {
      throw new Error("connection failed: this component not compatible");
    }
    if (!next.incoming.writable || !next.outgoing.readable) {
      throw new Error("connection failed: next component not compatible");
    }
    try {
      this.incoming.pipe(next.incoming);
      next.outgoing.pipe(this.outgoing);
    } catch (e) {
      throw new Error(`connection failed: ${e.message}`);
    }
    const incomingErrorHandler = (err) => {
      this.incoming.emit("error", err);
    };
    next.incoming.on("error", incomingErrorHandler);
    const outgoingErrorHandler = (err) => {
      next.outgoing.emit("error", err);
    };
    this.outgoing.on("error", outgoingErrorHandler);
    this.next = next;
    next.prev = this;
    this._incomingErrorHandler = incomingErrorHandler;
    this._outgoingErrorHandler = outgoingErrorHandler;
    return next;
  }
  /**
   * Disconnect the next connected component. When there is no next component
   * the function will just do nothing.
   * @return {Component} - A reference to this component.
   */
  disconnect() {
    const next = this.next;
    if (next !== null) {
      this.incoming.unpipe(next.incoming);
      next.outgoing.unpipe(this.outgoing);
      if (typeof this._incomingErrorHandler !== "undefined") {
        next.incoming.removeListener("error", this._incomingErrorHandler);
      }
      if (typeof this._outgoingErrorHandler !== "undefined") {
        this.outgoing.removeListener("error", this._outgoingErrorHandler);
      }
      this.next = null;
      next.prev = null;
      delete this._incomingErrorHandler;
      delete this._outgoingErrorHandler;
    }
    return this;
  }
};
var Tube = class _Tube extends Source {
  constructor(incoming = new PassThrough({ objectMode: true }), outgoing = new PassThrough({ objectMode: true })) {
    super(incoming, outgoing);
    __publicField(this, "incoming");
    __publicField(this, "outgoing");
    this.incoming = incoming;
    this.outgoing = outgoing;
  }
  /**
   * Create a component that calls a handler function for each message passing
   * through, but otherwise just passes data through.
   *
   * Can be used to log messages passing through a pipeline.
   */
  static fromHandlers(fnIncoming, fnOutgoing) {
    const incomingStream = fnIncoming ? StreamFactory.peeker(fnIncoming) : void 0;
    const outgoingStream = fnOutgoing ? StreamFactory.peeker(fnOutgoing) : void 0;
    return new _Tube(incomingStream, outgoingStream);
  }
};
var Sink = class _Sink extends AbstractComponent {
  constructor(incoming = new Writable2({ objectMode: true }), outgoing = new Readable2({ objectMode: true })) {
    super();
    __publicField(this, "incoming");
    __publicField(this, "outgoing");
    __publicField(this, "next");
    __publicField(this, "prev");
    this.incoming = incoming;
    this.outgoing = outgoing;
    this.next = null;
    this.prev = null;
  }
  /**
   * Create a component that swallows incoming data (calling fn on it).  To
   * print data, you would use fn = console.log.
   *
   * @param fn - The callback to use for the incoming data.
   */
  static fromHandler(fn) {
    const component = new _Sink(
      StreamFactory.consumer(fn),
      StreamFactory.producer(void 0)
    );
    component.incoming.on("finish", () => {
      component.outgoing.push(null);
    });
    return component;
  }
  connect() {
    throw new Error("connection failed: attempting to connect after a sink");
  }
  disconnect() {
    return this;
  }
};

// src/utils/bits.ts
var POS = [128, 64, 32, 16, 8, 4, 2, 1];

// src/utils/protocols/rtp.ts
var version = (buffer) => {
  return buffer[0] >>> 6;
};
var padding = (buffer) => {
  return !!(buffer[0] & POS[2]);
};
var extension = (buffer) => {
  return !!(buffer[0] & POS[3]);
};
var cSrcCount = (buffer) => {
  return buffer[0] & 15;
};
var marker = (buffer) => {
  return !!(buffer[1] & POS[0]);
};
var payloadType = (buffer) => {
  return buffer[1] & 127;
};
var sequenceNumber = (buffer) => {
  return buffer.readUInt16BE(2);
};
var timestamp = (buffer) => {
  return buffer.readUInt32BE(4);
};
var sSrc = (buffer) => {
  return buffer.readUInt32BE(8);
};
var cSrc = (buffer, rank = 0) => {
  return cSrcCount(buffer) > rank ? buffer.readUInt32BE(12 + rank * 4) : 0;
};
var extHeaderLength = (buffer) => {
  return !extension(buffer) ? 0 : buffer.readUInt16BE(12 + cSrcCount(buffer) * 4 + 2);
};
var extHeader = (buffer) => {
  return extHeaderLength(buffer) === 0 ? Buffer.from([]) : buffer.slice(
    12 + cSrcCount(buffer) * 4,
    12 + cSrcCount(buffer) * 4 + 4 + extHeaderLength(buffer) * 4
  );
};
var payload = (buffer) => {
  return !extension(buffer) ? buffer.slice(12 + cSrcCount(buffer) * 4) : buffer.slice(12 + cSrcCount(buffer) * 4 + 4 + extHeaderLength(buffer) * 4);
};

// src/components/message.ts
var MessageType = /* @__PURE__ */ ((MessageType2) => {
  MessageType2[MessageType2["UNKNOWN"] = 0] = "UNKNOWN";
  MessageType2[MessageType2["RAW"] = 1] = "RAW";
  MessageType2[MessageType2["RTP"] = 2] = "RTP";
  MessageType2[MessageType2["RTCP"] = 3] = "RTCP";
  MessageType2[MessageType2["RTSP"] = 4] = "RTSP";
  MessageType2[MessageType2["SDP"] = 5] = "SDP";
  MessageType2[MessageType2["ELEMENTARY"] = 6] = "ELEMENTARY";
  MessageType2[MessageType2["H264"] = 7] = "H264";
  MessageType2[MessageType2["ISOM"] = 8] = "ISOM";
  MessageType2[MessageType2["XML"] = 9] = "XML";
  MessageType2[MessageType2["JPEG"] = 10] = "JPEG";
  return MessageType2;
})(MessageType || {});

// src/components/messageStreams.ts
import { Transform as Transform2 } from "stream";
var createTransform = (transform) => {
  return new Transform2({
    objectMode: true,
    transform
  });
};

// src/components/aacdepay/parser.ts
function parse(rtp, hasHeader, callback) {
  const buffer = payload(rtp.data);
  let headerLength = 0;
  if (hasHeader) {
    const auHeaderLengthInBits = buffer.readUInt16BE(0);
    headerLength = 2 + (auHeaderLengthInBits + auHeaderLengthInBits % 8) / 8;
  }
  const packet = {
    type: 6 /* ELEMENTARY */,
    data: buffer.slice(headerLength),
    payloadType: payloadType(rtp.data),
    timestamp: timestamp(rtp.data),
    ntpTimestamp: rtp.ntpTimestamp
  };
  callback(packet);
}

// src/components/aacdepay/index.ts
var AACDepay = class extends Tube {
  constructor() {
    let AACPayloadType;
    let hasHeader;
    const incoming = createTransform(function(msg, encoding, callback) {
      if (msg.type === 5 /* SDP */) {
        let validMedia;
        for (const media of msg.sdp.media) {
          if (media.type === "audio" && media.fmtp && media.fmtp.parameters && media.fmtp.parameters.mode === "AAC-hbr") {
            validMedia = media;
          }
        }
        if (validMedia && validMedia.rtpmap !== void 0) {
          AACPayloadType = Number(validMedia.rtpmap.payloadType);
          const parameters = validMedia.fmtp.parameters;
          const sizeLength = Number(parameters.sizelength) || 0;
          const indexLength = Number(parameters.indexlength) || 0;
          const indexDeltaLength = Number(parameters.indexdeltalength) || 0;
          const CTSDeltaLength = Number(parameters.ctsdeltalength) || 0;
          const DTSDeltaLength = Number(parameters.dtsdeltalength) || 0;
          const RandomAccessIndication = Number(parameters.randomaccessindication) || 0;
          const StreamStateIndication = Number(parameters.streamstateindication) || 0;
          const AuxiliaryDataSizeLength = Number(parameters.auxiliarydatasizelength) || 0;
          hasHeader = sizeLength + Math.max(indexLength, indexDeltaLength) + CTSDeltaLength + DTSDeltaLength + RandomAccessIndication + StreamStateIndication + AuxiliaryDataSizeLength > 0;
        }
        callback(void 0, msg);
      } else if (msg.type === 2 /* RTP */ && payloadType(msg.data) === AACPayloadType) {
        parse(msg, hasHeader, this.push.bind(this));
        callback();
      } else {
        callback(void 0, msg);
      }
    });
    super(incoming);
  }
};

// src/components/basicdepay/index.ts
var BasicDepay = class extends Tube {
  constructor(rtpPayloadType) {
    if (rtpPayloadType === void 0) {
      throw new Error("you must supply a payload type to BasicDepayComponent");
    }
    let buffer = Buffer.alloc(0);
    const incoming = createTransform(function(msg, encoding, callback) {
      if (msg.type === 2 /* RTP */ && payloadType(msg.data) === rtpPayloadType) {
        const rtpPayload = payload(msg.data);
        buffer = Buffer.concat([buffer, rtpPayload]);
        if (marker(msg.data)) {
          if (buffer.length > 0) {
            this.push({
              data: buffer,
              timestamp: timestamp(msg.data),
              ntpTimestamp: msg.ntpTimestamp,
              payloadType: payloadType(msg.data),
              type: 6 /* ELEMENTARY */
            });
          }
          buffer = Buffer.alloc(0);
        }
        callback();
      } else {
        callback(void 0, msg);
      }
    });
    super(incoming);
  }
};

// src/components/canvas/index.ts
import { Readable as Readable3, Writable as Writable3 } from "stream";

// src/utils/clock.ts
var Clock = class {
  constructor() {
    __publicField(this, "started");
    __publicField(this, "stopped");
    __publicField(this, "elapsed");
    this.elapsed = 0;
    this.started = 0;
    this.stopped = true;
  }
  start() {
    if (this.stopped) {
      this.started = window.performance.now();
      this.stopped = false;
    }
  }
  stop() {
    if (!this.stopped) {
      this.elapsed = this.now();
      this.stopped = true;
    }
  }
  reset() {
    this.elapsed = 0;
    this.started = 0;
    this.stopped = true;
  }
  // Gives the elapsed time in milliseconds since the
  // clock was first started (after last reset).
  now() {
    if (this.stopped) {
      return this.elapsed;
    }
    return this.elapsed + (window.performance.now() - this.started);
  }
  play() {
    this.start();
  }
  pause() {
    this.stop();
  }
  // Gives the elapsed time in seconds since last reset.
  get currentTime() {
    return this.now() / 1e3;
  }
};

// src/utils/scheduler.ts
var DEFAULT_TOLERANCE = 10;
var Scheduler = class {
  /**
   * Creates an instance of Scheduler.
   * @param clock - The clock to use (so we can control playback)
   * @param handler - The callback to invoke when a message is in sync
   * @param tolerance - The milliseconds defining "in sync" (default = 10)
   */
  constructor(clock, handler, tolerance = DEFAULT_TOLERANCE) {
    __publicField(this, "_clock");
    __publicField(this, "_handler");
    __publicField(this, "_tolerance");
    __publicField(this, "_nextRun");
    __publicField(this, "_nextPlay");
    __publicField(this, "_fifo");
    __publicField(this, "_ntpPresentationTime");
    __publicField(this, "_suspended");
    this._clock = clock;
    this._handler = handler;
    this._tolerance = tolerance;
    this._nextRun = 0;
    this._nextPlay = 0;
    this._fifo = [];
    this._ntpPresentationTime = 0;
    this._suspended = false;
  }
  /**
   * Bring the scheduler back to it's initial state.
   */
  reset() {
    clearTimeout(this._nextRun);
    clearTimeout(this._nextPlay);
    this._fifo = [];
    this._ntpPresentationTime = 0;
    this._suspended = false;
  }
  /**
   * Initialize the scheduler.
   *
   * @param ntpPresentationTime - The offset representing the start of the presentation
   */
  init(ntpPresentationTime) {
    this._ntpPresentationTime = ntpPresentationTime;
  }
  /**
   * Suspend the scheduler.
   *
   * This releases control of the clock and stops any scheduling activity.
   * Note that this doesn't mean the clock will be in a particular state
   * (could be started or stopped), just that the scheduler will no longer
   * control it.
   */
  suspend() {
    clearTimeout(this._nextPlay);
    this._suspended = true;
  }
  /**
   * Resume the scheduler.
   *
   * This gives back control of the clock and the ability
   * to schedule messages. The scheduler will immediately
   * try to do that on resume.
   */
  resume() {
    this._suspended = false;
    this.run(void 0);
  }
  /**
   * Run the scheduler.
   *
   * @param newMessage - New message to schedule.
   */
  run(newMessage) {
    clearTimeout(this._nextRun);
    if (typeof this._ntpPresentationTime === "undefined") {
      return;
    }
    if (typeof newMessage !== "undefined") {
      this._fifo.push(newMessage);
    }
    if (this._suspended) {
      return;
    }
    if (this._fifo.length === 0) {
      return;
    }
    let timeToPresent = 0;
    let currentMessage;
    do {
      const msg = this._fifo.shift();
      if (msg === void 0) {
        throw new Error("internal error: message should never be undefined");
      }
      currentMessage = msg;
      const ntpTimestamp = currentMessage.ntpTimestamp;
      if (ntpTimestamp === void 0) {
        continue;
      }
      const presentationTime = ntpTimestamp - this._ntpPresentationTime;
      timeToPresent = presentationTime - this._clock.currentTime * 1e3;
      if (Math.abs(timeToPresent) < this._tolerance) {
        this._handler && this._handler(currentMessage);
      }
    } while (timeToPresent < this._tolerance && this._fifo.length > 0);
    if (timeToPresent < -this._tolerance) {
      clearTimeout(this._nextPlay);
      this._clock.pause();
      this._nextPlay = window.setTimeout(
        () => this._clock.play(),
        -timeToPresent
      );
    } else if (timeToPresent > this._tolerance) {
      this._fifo.unshift(currentMessage);
      this._nextRun = window.setTimeout(
        () => this.run(void 0),
        timeToPresent
      );
    }
  }
};

// src/components/canvas/index.ts
var resetInfo = (info) => {
  info.bitrate = 0;
  info.framerate = 0;
  info.renderedFrames = 0;
};
var generateUpdateInfo = (clockrate) => {
  let cumulativeByteLength = 0;
  let cumulativeDuration = 0;
  let cumulativeFrames = 0;
  return (info, { byteLength, duration }) => {
    cumulativeByteLength += byteLength;
    cumulativeDuration += duration;
    cumulativeFrames++;
    if (cumulativeDuration >= clockrate) {
      const bits = 8 * cumulativeByteLength;
      const frames = cumulativeFrames;
      const seconds = cumulativeDuration / clockrate;
      info.bitrate = bits / seconds;
      info.framerate = frames / seconds;
      cumulativeByteLength = 0;
      cumulativeDuration = 0;
      cumulativeFrames = 0;
    }
  };
};
var CanvasSink = class extends Sink {
  /**
   * @param  el - The <canvas> element to draw incoming JPEG messages on.
   */
  constructor(el) {
    if (el === void 0) {
      throw new Error("canvas element argument missing");
    }
    let firstTimestamp = 0;
    let lastTimestamp = 0;
    let clockrate = 0;
    const info = {
      bitrate: 0,
      framerate: 0,
      renderedFrames: 0
    };
    let updateInfo;
    let ctx = null;
    if (window.createImageBitmap !== void 0) {
      ctx = el.getContext("bitmaprenderer");
    }
    if (ctx === null) {
      ctx = el.getContext("2d");
    }
    let drawImageBlob;
    if (ctx === null) {
      drawImageBlob = () => {
      };
    } else if ("transferFromImageBitmap" in ctx) {
      const ctxBitmaprenderer = ctx;
      drawImageBlob = ({ blob }) => {
        info.renderedFrames++;
        window.createImageBitmap(blob).then((imageBitmap) => {
          ctxBitmaprenderer.transferFromImageBitmap(imageBitmap);
        }).catch(() => {
        });
      };
    } else {
      const ctx2d = ctx;
      const img = new Image();
      img.onload = () => {
        ctx2d.drawImage(img, 0, 0);
      };
      drawImageBlob = ({ blob }) => {
        info.renderedFrames++;
        const url = window.URL.createObjectURL(blob);
        img.src = url;
      };
    }
    const clock = new Clock();
    const scheduler = new Scheduler(clock, drawImageBlob);
    let ntpPresentationTime = 0;
    const onCanplay = () => {
      this.onCanplay && this.onCanplay();
    };
    const onSync = (npt) => {
      this.onSync && this.onSync(npt);
    };
    const incoming = new Writable3({
      objectMode: true,
      write: (msg, _encoding, callback) => {
        if (msg.type === 5 /* SDP */) {
          clock.reset();
          scheduler.reset();
          firstTimestamp = 0;
          const jpegMedia = msg.sdp.media.find((media) => {
            return media.type === "video" && media.rtpmap !== void 0 && media.rtpmap.encodingName === "JPEG";
          });
          if (jpegMedia !== void 0 && jpegMedia.rtpmap !== void 0) {
            clockrate = jpegMedia.rtpmap.clockrate;
            resetInfo(info);
            updateInfo = generateUpdateInfo(clockrate);
          }
          callback();
        } else if (msg.type === 10 /* JPEG */) {
          const { timestamp: timestamp2, ntpTimestamp } = msg;
          if (!firstTimestamp) {
            firstTimestamp = timestamp2;
            lastTimestamp = timestamp2;
            const { width, height } = msg.framesize;
            el.width = width;
            el.height = height;
            scheduler.init(0);
          }
          const presentationTime = 1e3 * (timestamp2 - firstTimestamp) / clockrate;
          const blob = new window.Blob([msg.data], { type: "image/jpeg" });
          if (!ntpPresentationTime && ntpTimestamp) {
            ntpPresentationTime = ntpTimestamp - presentationTime;
            onSync(ntpPresentationTime);
          }
          scheduler.run({
            ntpTimestamp: presentationTime,
            blob
          });
          if (timestamp2 === firstTimestamp) {
            onCanplay();
          }
          updateInfo(info, {
            byteLength: msg.data.length,
            duration: timestamp2 - lastTimestamp
          });
          lastTimestamp = timestamp2;
          callback();
        } else {
          callback();
        }
      }
    });
    const outgoing = new Readable3({
      objectMode: true,
      read() {
      }
    });
    outgoing.on("error", () => {
      console.warn("outgoing stream broke somewhere");
    });
    super(incoming, outgoing);
    __publicField(this, "onCanplay");
    __publicField(this, "onSync");
    __publicField(this, "_clock");
    __publicField(this, "_scheduler");
    __publicField(this, "_info");
    this._clock = clock;
    this._scheduler = scheduler;
    this._info = info;
    this.onCanplay = void 0;
    this.onSync = void 0;
  }
  /**
   * Retrieve the current presentation time (seconds)
   */
  get currentTime() {
    return this._clock.currentTime;
  }
  /**
   * Pause the presentation.
   */
  pause() {
    this._scheduler.suspend();
    this._clock.pause();
  }
  /**
   * Start the presentation.
   */
  play() {
    this._clock.play();
    this._scheduler.resume();
  }
  get bitrate() {
    return this._info.bitrate;
  }
  get framerate() {
    return this._info.framerate;
  }
};

// src/components/h264depay/index.ts
import { Transform as Transform3 } from "stream";

// src/components/h264depay/parser.ts
import debug from "debug";
var h264Debug = debug("msl:h264depay");
var H264DepayParser = class {
  constructor() {
    __publicField(this, "_buffer");
    this._buffer = Buffer.alloc(0);
  }
  parse(rtp) {
    const rtpPayload = payload(rtp.data);
    const type = rtpPayload[0] & 31;
    if (type === 28) {
      const fuIndicator = rtpPayload[0];
      const fuHeader = rtpPayload[1];
      const startBit = !!(fuHeader >> 7);
      const nalType = fuHeader & 31;
      const nal = fuIndicator & 224 | nalType;
      const stopBit = fuHeader & 64;
      if (startBit) {
        this._buffer = Buffer.concat([
          Buffer.from([0, 0, 0, 0, nal]),
          rtpPayload.slice(2)
        ]);
        return null;
      } else if (stopBit) {
        const h264frame = Buffer.concat([
          this._buffer,
          rtpPayload.slice(2)
        ]);
        h264frame.writeUInt32BE(h264frame.length - 4, 0);
        const msg = {
          data: h264frame,
          type: 7 /* H264 */,
          timestamp: timestamp(rtp.data),
          ntpTimestamp: rtp.ntpTimestamp,
          payloadType: payloadType(rtp.data),
          nalType
        };
        this._buffer = Buffer.alloc(0);
        return msg;
      }
      this._buffer = Buffer.concat([this._buffer, rtpPayload.slice(2)]);
      return null;
    } else if ((type === 1 /* NON_IDR_PICTURE */ || type === 5 /* IDR_PICTURE */) && this._buffer.length === 0) {
      const h264frame = Buffer.concat([
        Buffer.from([0, 0, 0, 0]),
        rtpPayload
      ]);
      h264frame.writeUInt32BE(h264frame.length - 4, 0);
      const msg = {
        data: h264frame,
        type: 7 /* H264 */,
        timestamp: timestamp(rtp.data),
        ntpTimestamp: rtp.ntpTimestamp,
        payloadType: payloadType(rtp.data),
        nalType: type
      };
      this._buffer = Buffer.alloc(0);
      return msg;
    }
    h264Debug(
      `H264depayComponent can only extract types 1,5 and 28, got ${type}`
    );
    this._buffer = Buffer.alloc(0);
    return null;
  }
};

// src/components/h264depay/index.ts
var H264Depay = class extends Tube {
  constructor() {
    let h264PayloadType;
    let idrFound = false;
    let packets = [];
    const h264DepayParser = new H264DepayParser();
    const incoming = new Transform3({
      objectMode: true,
      transform(msg, _encoding, callback) {
        if (msg.type === 5 /* SDP */) {
          const h264Media = msg.sdp.media.find((media) => {
            return media.type === "video" && media.rtpmap !== void 0 && media.rtpmap.encodingName === "H264";
          });
          if (h264Media !== void 0 && h264Media.rtpmap !== void 0) {
            h264PayloadType = h264Media.rtpmap.payloadType;
          }
          callback(void 0, msg);
        } else if (msg.type === 2 /* RTP */ && payloadType(msg.data) === h264PayloadType) {
          const endOfFrame = marker(msg.data);
          const h264Message = h264DepayParser.parse(msg);
          if (h264Message === null || !idrFound && h264Message.nalType !== 5 /* IDR_PICTURE */) {
            callback();
            return;
          }
          idrFound = true;
          packets.push(h264Message.data);
          if (endOfFrame) {
            this.push(__spreadProps(__spreadValues({}, h264Message), {
              data: packets.length === 1 ? packets[0] : Buffer.concat(packets)
            }));
            packets = [];
          }
          callback();
        } else {
          callback(void 0, msg);
        }
      }
    });
    super(incoming);
  }
};

// src/components/http-source/index.ts
import registerDebug from "debug";
import { Readable as Readable4 } from "stream";
var debug2 = registerDebug("msl:http-source");
var HttpSource = class extends Source {
  /**
   * Create an HTTP component.
   *
   * The constructor sets a single readable stream from a fetch.
   */
  constructor(config) {
    const { uri, options } = config;
    const incoming = new Readable4({
      objectMode: true,
      read() {
      }
    });
    incoming.on("error", (e) => {
      console.warn("closing socket due to incoming error", e);
      this._reader && this._reader.cancel().catch((err) => console.error(err));
    });
    super(incoming);
    __publicField(this, "uri");
    __publicField(this, "options");
    __publicField(this, "length");
    __publicField(this, "onHeaders");
    __publicField(this, "onServerClose");
    __publicField(this, "_reader");
    __publicField(this, "_abortController");
    __publicField(this, "_allDone");
    incoming._read = () => {
      this._pull();
    };
    this.uri = uri;
    this.options = options;
    this._allDone = false;
  }
  play() {
    if (this.uri === void 0) {
      throw new Error("cannot start playing when there is no URI");
    }
    this._abortController = new AbortController();
    this.length = 0;
    fetch(this.uri, __spreadValues({
      credentials: "include",
      signal: this._abortController.signal
    }, this.options)).then((rsp) => {
      if (rsp.body === null) {
        throw new Error("empty response body");
      }
      this.onHeaders && this.onHeaders(rsp.headers);
      this._reader = rsp.body.getReader();
      this._pull();
    }).catch((err) => {
      console.error("http-source: fetch failed: ", err);
    });
  }
  abort() {
    this._reader && this._reader.cancel().catch((err) => {
      console.log("http-source: cancel reader failed: ", err);
    });
    this._abortController && this._abortController.abort();
  }
  _isClosed() {
    return this._allDone;
  }
  _close() {
    var _a;
    this._reader = void 0;
    this._allDone = true;
    this.incoming.push(null);
    (_a = this.onServerClose) == null ? void 0 : _a.call(this);
  }
  _pull() {
    if (this._reader === void 0) {
      return;
    }
    this._reader.read().then(({ done, value }) => {
      if (done) {
        if (!this._isClosed()) {
          debug2("fetch completed, total downloaded: ", this.length, " bytes");
          this._close();
        }
        return;
      }
      if (value === void 0) {
        throw new Error("expected value to be defined");
      }
      if (this.length === void 0) {
        throw new Error("expected length to be defined");
      }
      this.length += value.length;
      const buffer = Buffer.from(value);
      if (!this.incoming.push({ data: buffer, type: 1 /* RAW */ })) {
        debug2("downstream back pressure: pausing read");
      } else {
        this._pull();
      }
    }).catch((err) => {
      debug2("http-source: read failed: ", err);
      if (!this._isClosed()) {
        this._close();
      }
    });
  }
};

// src/components/inspector/index.ts
import { Transform as Transform4 } from "stream";
var generateLogger = (prefix, type) => {
  let lastTimestamp = Date.now();
  const log = (msg) => {
    const timestamp2 = Date.now();
    console.log(`${prefix}: +${timestamp2 - lastTimestamp}ms`, msg);
    lastTimestamp = timestamp2;
  };
  if (type === void 0) {
    return log;
  }
  return (msg) => msg.type === type && log(msg);
};
var Inspector = class extends Tube {
  /**
   * Create a new inspector component.
   * @argument {String} type  The type of message to log (default is to log all).
   * @return {undefined}
   */
  constructor(type) {
    const incomingLogger = generateLogger("incoming", type);
    const incoming = new Transform4({
      objectMode: true,
      transform(msg, encoding, callback) {
        incomingLogger(msg);
        callback(void 0, msg);
      }
    });
    const outgoingLogger = generateLogger("outgoing", type);
    const outgoing = new Transform4({
      objectMode: true,
      transform(msg, encoding, callback) {
        outgoingLogger(msg);
        callback(void 0, msg);
      }
    });
    super(incoming, outgoing);
  }
};

// src/components/jpegdepay/index.ts
import { Transform as Transform5 } from "stream";

// src/components/jpegdepay/headers.ts
function makeImageHeader() {
  return Buffer.from([255, 216]);
}
function makeQuantHeader(precision, qTable) {
  const lumSize = precision & 1 ? 128 : 64;
  const chmSize = precision & 2 ? 128 : 64;
  if (qTable.length !== lumSize + chmSize) {
    throw new Error("invalid quantization table");
  }
  const lumaPrefix = Buffer.from([255, 219, 0, lumSize + 3, 0]);
  const chromaPrefix = Buffer.from([255, 219, 0, chmSize + 3, 1]);
  return Buffer.concat([
    lumaPrefix,
    qTable.slice(0, lumSize),
    chromaPrefix,
    qTable.slice(lumSize)
  ]);
}
function makeFrameHeader(width, height, type) {
  return Buffer.from([
    255,
    192,
    // SOF_0 (Start Of Frame)
    0,
    17,
    8,
    height >> 8,
    height,
    width >> 8,
    width,
    3,
    0,
    type === 0 ? 33 : 34,
    0,
    1,
    17,
    1,
    2,
    17,
    1
  ]);
}
var LUM_DC_CODELENS = [
  0,
  1,
  5,
  1,
  1,
  1,
  1,
  1,
  1,
  0,
  0,
  0,
  0,
  0,
  0,
  0
];
var LUM_DC_SYMBOLS = [
  0,
  1,
  2,
  3,
  4,
  5,
  6,
  7,
  8,
  9,
  10,
  11
];
var LUM_AC_CODELENS = [
  0,
  2,
  1,
  3,
  3,
  2,
  4,
  3,
  5,
  5,
  4,
  4,
  0,
  0,
  1,
  125
];
var LUM_AC_SYMBOLS = [
  1,
  2,
  3,
  0,
  4,
  17,
  5,
  18,
  33,
  49,
  65,
  6,
  19,
  81,
  97,
  7,
  34,
  113,
  20,
  50,
  129,
  145,
  161,
  8,
  35,
  66,
  177,
  193,
  21,
  82,
  209,
  240,
  36,
  51,
  98,
  114,
  130,
  9,
  10,
  22,
  23,
  24,
  25,
  26,
  37,
  38,
  39,
  40,
  41,
  42,
  52,
  53,
  54,
  55,
  56,
  57,
  58,
  67,
  68,
  69,
  70,
  71,
  72,
  73,
  74,
  83,
  84,
  85,
  86,
  87,
  88,
  89,
  90,
  99,
  100,
  101,
  102,
  103,
  104,
  105,
  106,
  115,
  116,
  117,
  118,
  119,
  120,
  121,
  122,
  131,
  132,
  133,
  134,
  135,
  136,
  137,
  138,
  146,
  147,
  148,
  149,
  150,
  151,
  152,
  153,
  154,
  162,
  163,
  164,
  165,
  166,
  167,
  168,
  169,
  170,
  178,
  179,
  180,
  181,
  182,
  183,
  184,
  185,
  186,
  194,
  195,
  196,
  197,
  198,
  199,
  200,
  201,
  202,
  210,
  211,
  212,
  213,
  214,
  215,
  216,
  217,
  218,
  225,
  226,
  227,
  228,
  229,
  230,
  231,
  232,
  233,
  234,
  241,
  242,
  243,
  244,
  245,
  246,
  247,
  248,
  249,
  250
];
var CHM_DC_CODELENS = [
  0,
  3,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  1,
  0,
  0,
  0,
  0,
  0
];
var CHM_DC_SYMBOLS = [
  0,
  1,
  2,
  3,
  4,
  5,
  6,
  7,
  8,
  9,
  10,
  11
];
var CHM_AC_CODELENS = [
  0,
  2,
  1,
  2,
  4,
  4,
  3,
  4,
  7,
  5,
  4,
  4,
  0,
  1,
  2,
  119
];
var CHM_AC_SYMBOLS = [
  0,
  1,
  2,
  3,
  17,
  4,
  5,
  33,
  49,
  6,
  18,
  65,
  81,
  7,
  97,
  113,
  19,
  34,
  50,
  129,
  8,
  20,
  66,
  145,
  161,
  177,
  193,
  9,
  35,
  51,
  82,
  240,
  21,
  98,
  114,
  209,
  10,
  22,
  36,
  52,
  225,
  37,
  241,
  23,
  24,
  25,
  26,
  38,
  39,
  40,
  41,
  42,
  53,
  54,
  55,
  56,
  57,
  58,
  67,
  68,
  69,
  70,
  71,
  72,
  73,
  74,
  83,
  84,
  85,
  86,
  87,
  88,
  89,
  90,
  99,
  100,
  101,
  102,
  103,
  104,
  105,
  106,
  115,
  116,
  117,
  118,
  119,
  120,
  121,
  122,
  130,
  131,
  132,
  133,
  134,
  135,
  136,
  137,
  138,
  146,
  147,
  148,
  149,
  150,
  151,
  152,
  153,
  154,
  162,
  163,
  164,
  165,
  166,
  167,
  168,
  169,
  170,
  178,
  179,
  180,
  181,
  182,
  183,
  184,
  185,
  186,
  194,
  195,
  196,
  197,
  198,
  199,
  200,
  201,
  202,
  210,
  211,
  212,
  213,
  214,
  215,
  216,
  217,
  218,
  226,
  227,
  228,
  229,
  230,
  231,
  232,
  233,
  234,
  242,
  243,
  244,
  245,
  246,
  247,
  248,
  249,
  250
];
function makeHuffmanHeader() {
  const LUM_DC_BUFFER = [
    [
      255,
      196,
      0,
      3 + LUM_DC_CODELENS.length + LUM_DC_SYMBOLS.length,
      0 << 4 | 0
    ],
    LUM_DC_CODELENS,
    LUM_DC_SYMBOLS
  ];
  const LUM_AC_BUFFER = [
    [
      255,
      196,
      0,
      3 + LUM_AC_CODELENS.length + LUM_AC_SYMBOLS.length,
      1 << 4 | 0
    ],
    LUM_AC_CODELENS,
    LUM_AC_SYMBOLS
  ];
  const CHM_DC_BUFFER = [
    [
      255,
      196,
      0,
      3 + CHM_DC_CODELENS.length + CHM_DC_SYMBOLS.length,
      0 << 4 | 1
    ],
    CHM_DC_CODELENS,
    CHM_DC_SYMBOLS
  ];
  const CHM_AC_BUFFER = [
    [
      255,
      196,
      0,
      3 + CHM_AC_CODELENS.length + CHM_AC_SYMBOLS.length,
      1 << 4 | 1
    ],
    CHM_AC_CODELENS,
    CHM_AC_SYMBOLS
  ];
  return Buffer.concat([
    ...LUM_DC_BUFFER.map(Buffer.from),
    ...LUM_AC_BUFFER.map(Buffer.from),
    ...CHM_DC_BUFFER.map(Buffer.from),
    ...CHM_AC_BUFFER.map(Buffer.from)
  ]);
}
function makeScanHeader() {
  return Buffer.from([
    255,
    218,
    // SOS (Start Of Scan)
    0,
    12,
    3,
    0,
    0,
    1,
    17,
    2,
    17,
    0,
    63,
    0
  ]);
}
function makeDRIHeader(dri) {
  return Buffer.from([255, 221, 0, 4, dri >> 8, dri & 255]);
}

// src/utils/clamp.ts
function clamp(val, min, max) {
  return val > max ? max : val < min ? min : val;
}

// src/components/jpegdepay/make-qtable.ts
var jpegLumaQuantizer = [
  16,
  11,
  12,
  14,
  12,
  10,
  16,
  14,
  13,
  14,
  18,
  17,
  16,
  19,
  24,
  40,
  26,
  24,
  22,
  22,
  24,
  49,
  35,
  37,
  29,
  40,
  58,
  51,
  61,
  60,
  57,
  51,
  56,
  55,
  64,
  72,
  92,
  78,
  64,
  68,
  87,
  69,
  55,
  56,
  80,
  109,
  81,
  87,
  95,
  98,
  103,
  104,
  103,
  62,
  77,
  113,
  121,
  112,
  100,
  120,
  92,
  101,
  103,
  99
];
var jpeChromaQuantizer = [
  17,
  18,
  18,
  24,
  21,
  24,
  47,
  26,
  26,
  47,
  99,
  66,
  56,
  66,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99,
  99
];
function makeQtable(Q) {
  const factor = clamp(Q, 1, 99);
  const buffer = Buffer.alloc(128);
  const S = Q < 50 ? Math.floor(5e3 / factor) : 200 - factor * 2;
  for (let i = 0; i < 64; i++) {
    const lq = Math.floor((jpegLumaQuantizer[i] * S + 50) / 100);
    const cq = Math.floor((jpeChromaQuantizer[i] * S + 50) / 100);
    buffer.writeUInt8(clamp(lq, 1, 255), i);
    buffer.writeUInt8(clamp(cq, 1, 255), i + 64);
  }
  return buffer;
}

// src/components/jpegdepay/parser.ts
function jpegDepayFactory(defaultWidth = 0, defaultHeight = 0) {
  const IMAGE_HEADER = makeImageHeader();
  const HUFFMAN_HEADER = makeHuffmanHeader();
  const SCAN_HEADER = makeScanHeader();
  return function jpegDepay(packets) {
    let metadata;
    const fragments = [];
    for (const packet of packets) {
      let fragment = payload(packet);
      const typeSpecific = fragment.readUInt8(0);
      const fragmentOffset = fragment.readUInt8(1) << 16 | fragment.readUInt8(2) << 8 | fragment.readUInt8(3);
      const type2 = fragment.readUInt8(4);
      const Q = fragment.readUInt8(5);
      const width2 = fragment.readUInt8(6) * 8 || defaultWidth;
      const height2 = fragment.readUInt8(7) * 8 || defaultHeight;
      fragment = fragment.slice(8);
      let DRI = 0;
      if (type2 >= 64 && type2 <= 127) {
        DRI = fragment.readUInt16BE(0);
        fragment = fragment.slice(4);
      }
      if (Q >= 128 && fragmentOffset === 0) {
        const precision2 = fragment.readUInt8(1);
        const length = fragment.readUInt16BE(2);
        const qTable2 = fragment.slice(4, 4 + length);
        metadata = {
          typeSpecific,
          type: type2,
          width: width2,
          height: height2,
          DRI,
          precision: precision2,
          qTable: qTable2
        };
        fragment = fragment.slice(4 + length);
      } else if (Q < 128 && fragmentOffset === 0) {
        const precision2 = 0;
        const qTable2 = makeQtable(Q);
        metadata = {
          typeSpecific,
          type: type2,
          width: width2,
          height: height2,
          DRI,
          precision: precision2,
          qTable: qTable2
        };
      }
      fragments.push(fragment);
    }
    if (metadata === void 0) {
      throw new Error("no quantization header present");
    }
    const { precision, qTable, type, width, height } = metadata;
    const quantHeader = makeQuantHeader(precision, qTable);
    const driHeader = metadata.DRI === 0 ? Buffer.alloc(0) : makeDRIHeader(metadata.DRI);
    const frameHeader = makeFrameHeader(width, height, type);
    return {
      size: { width, height },
      data: Buffer.concat([
        IMAGE_HEADER,
        quantHeader,
        driHeader,
        frameHeader,
        HUFFMAN_HEADER,
        SCAN_HEADER,
        ...fragments
      ])
    };
  };
}

// src/components/jpegdepay/index.ts
var JPEGDepay = class extends Tube {
  constructor() {
    let jpegPayloadType;
    let packets = [];
    let jpegDepay;
    const incoming = new Transform5({
      objectMode: true,
      transform(msg, encoding, callback) {
        if (msg.type === 5 /* SDP */) {
          const jpegMedia = msg.sdp.media.find((media) => {
            return media.type === "video" && media.rtpmap !== void 0 && media.rtpmap.encodingName === "JPEG";
          });
          if (jpegMedia !== void 0 && jpegMedia.rtpmap !== void 0) {
            jpegPayloadType = Number(jpegMedia.rtpmap.payloadType);
            const framesize = jpegMedia.framesize;
            if (framesize !== void 0) {
              const [width, height] = framesize;
              jpegDepay = jpegDepayFactory(width, height);
            } else {
              jpegDepay = jpegDepayFactory();
            }
          }
          callback(void 0, msg);
        } else if (msg.type === 2 /* RTP */ && payloadType(msg.data) === jpegPayloadType) {
          packets.push(msg.data);
          if (marker(msg.data) && packets.length > 0) {
            const jpegFrame = jpegDepay(packets);
            this.push({
              timestamp: timestamp(msg.data),
              ntpTimestamp: msg.ntpTimestamp,
              payloadType: payloadType(msg.data),
              data: jpegFrame.data,
              framesize: jpegFrame.size,
              type: 10 /* JPEG */
            });
            packets = [];
          }
          callback();
        } else {
          callback(void 0, msg);
        }
      }
    });
    super(incoming);
  }
};

// src/components/mp4capture/index.ts
import debug3 from "debug";
import { Transform as Transform6 } from "stream";
var MAX_CAPTURE_BYTES = 225e6;
var Mp4Capture = class extends Tube {
  constructor(maxSize = MAX_CAPTURE_BYTES) {
    const incoming = new Transform6({
      objectMode: true,
      transform: (msg, _encoding, callback) => {
        if (this._active && msg.type === 8 /* ISOM */ && msg.tracks !== void 0) {
          this._capture = true;
        }
        if (this._capture && msg.type === 8 /* ISOM */) {
          if (this._bufferOffset < this._buffer.byteLength - msg.data.byteLength) {
            msg.data.copy(this._buffer, this._bufferOffset);
            this._bufferOffset += msg.data.byteLength;
          } else {
            this.stop();
          }
        }
        callback(void 0, msg);
      }
    });
    incoming.on("finish", () => {
      this.stop();
    });
    super(incoming);
    __publicField(this, "_active");
    __publicField(this, "_capture");
    __publicField(this, "_captureCallback");
    __publicField(this, "_bufferOffset");
    __publicField(this, "_bufferSize");
    __publicField(this, "_buffer");
    this._buffer = Buffer.allocUnsafe(0);
    this._bufferSize = maxSize;
    this._bufferOffset = 0;
    this._active = false;
    this._capture = false;
    this._captureCallback = () => {
    };
  }
  /**
   * Activate video capture. The capture will begin when a new movie starts,
   * and will terminate when the movie ends or when the buffer is full. On
   * termination, the callback you passed will be called with the captured
   * data as argument.
   * @param callback  Will be called when data is captured.
   */
  start(callback) {
    if (!this._active) {
      debug3("msl:capture:start")(callback);
      this._captureCallback = callback;
      this._buffer = Buffer.allocUnsafe(this._bufferSize);
      this._bufferOffset = 0;
      this._active = true;
    }
  }
  /**
   * Deactivate video capture. This ends an ongoing capture and prevents
   * any further capturing.
   */
  stop() {
    if (this._active) {
      debug3("msl:capture:stop")(`captured bytes: ${this._bufferOffset}`);
      try {
        this._captureCallback(this._buffer.slice(0, this._bufferOffset));
      } catch (e) {
        console.error(e);
      }
      this._buffer = Buffer.allocUnsafe(0);
      this._bufferOffset = 0;
      this._active = false;
      this._capture = false;
    }
  }
};

// src/components/mp4muxer/index.ts
import debug4 from "debug";
import { Transform as Transform7 } from "stream";

// src/components/mp4muxer/helpers/isom.ts
var UINT32_RANGE = Math.pow(2, 32);
var BoxElement = class {
  constructor(size) {
    __publicField(this, "byteLength");
    __publicField(this, "value");
    this.byteLength = size;
  }
};
var Empty = class extends BoxElement {
  constructor(size = 0) {
    super(size);
    __publicField(this, "copy", (buffer, offset) => {
      buffer.fill(0, offset, offset + this.byteLength);
    });
  }
  load() {
  }
};
var CharArray = class extends BoxElement {
  constructor(s) {
    super(s.length);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      for (let i = 0; i < this.byteLength; i += 1) {
        buffer[offset + i] = this.value.charCodeAt(i);
      }
    });
    __publicField(this, "load", (buffer, offset) => {
      this.value = buffer.slice(offset, offset + this.byteLength).toString("ascii");
    });
    this.value = s;
  }
};
var UInt8 = class extends BoxElement {
  constructor(scalar = 0) {
    super(1);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      buffer.writeUInt8(this.value, offset);
    });
    __publicField(this, "load", (buffer, offset) => {
      this.value = buffer.readUInt8(offset);
    });
    this.value = scalar;
  }
};
var UInt8Array = class extends BoxElement {
  constructor(array) {
    super(array.length);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      for (let i = 0; i < this.value.length; ++i) {
        buffer.writeUInt8(this.value[i], offset + i);
      }
    });
    __publicField(this, "load", (buffer, offset) => {
      for (let i = 0; i < this.value.length; ++i) {
        this.value[i] = buffer.readUInt8(offset + i);
      }
    });
    this.value = array;
  }
};
var UInt16BE = class extends BoxElement {
  constructor(scalar = 0) {
    super(2);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      buffer.writeUInt16BE(this.value, offset);
    });
    __publicField(this, "load", (buffer, offset) => {
      this.value = buffer.readUInt16BE(offset);
    });
    this.value = scalar;
  }
};
var UInt24BE = class extends BoxElement {
  constructor(scalar = 0) {
    super(3);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      buffer.writeUInt8(this.value >> 16 & 255, offset);
      buffer.writeUInt8(this.value >> 8 & 255, offset + 1);
      buffer.writeUInt8(this.value & 255, offset + 2);
    });
    __publicField(this, "load", (buffer, offset) => {
      this.value = buffer.readUInt8(offset) << 16 + buffer.readUInt8(offset + 1) << 8 + buffer.readUInt8(offset + 2);
    });
    this.value = scalar;
  }
};
var UInt16BEArray = class extends BoxElement {
  constructor(array) {
    super(array.length * 2);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      for (let i = 0; i < this.value.length; ++i) {
        buffer.writeUInt16BE(this.value[i], offset + 2 * i);
      }
    });
    __publicField(this, "load", (buffer, offset) => {
      for (let i = 0; i < this.value.length; ++i) {
        this.value[i] = buffer.readUInt16BE(offset + 2 * i);
      }
    });
    this.value = array;
  }
};
var UInt32BE = class extends BoxElement {
  constructor(scalar = 0) {
    super(4);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      buffer.writeUInt32BE(this.value, offset);
    });
    __publicField(this, "load", (buffer, offset) => {
      this.value = buffer.readUInt32BE(offset);
    });
    this.value = scalar;
  }
};
var UInt32BEArray = class extends BoxElement {
  constructor(array) {
    super(array.length * 4);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      for (let i = 0; i < this.value.length; ++i) {
        buffer.writeUInt32BE(this.value[i], offset + 4 * i);
      }
    });
    __publicField(this, "load", (buffer, offset) => {
      for (let i = 0; i < this.value.length; ++i) {
        this.value[i] = buffer.readUInt32BE(offset + 4 * i);
      }
    });
    this.value = array;
  }
};
var UInt64BE = class extends BoxElement {
  constructor(scalar = 0) {
    super(8);
    __publicField(this, "value");
    __publicField(this, "copy", (buffer, offset) => {
      const high = this.value / UINT32_RANGE | 0;
      const low = this.value - high * UINT32_RANGE;
      buffer.writeUInt32BE(high, offset);
      buffer.writeUInt32BE(low, offset + 4);
    });
    __publicField(this, "load", (buffer, offset) => {
      const high = buffer.readUInt32BE(offset);
      const low = buffer.readUInt32BE(offset + 4);
      this.value = high * UINT32_RANGE + low;
    });
    this.value = scalar;
  }
};
var createParameterSetArrayClass = function(sizeMask = 0) {
  return class ParameterSetArray extends BoxElement {
    /**
     * Takes an array of byte-arrays
     * @param  array The array of byte arrays
     */
    constructor(array) {
      super(0);
      __publicField(this, "value");
      __publicField(this, "copy", (buffer, offset) => {
        let i = 0;
        for (const element of this.value) {
          element.copy(buffer, offset + i);
          i += element.byteLength;
        }
      });
      __publicField(this, "load", () => {
      });
      this.value = array.reduce(
        (flatArray, byteArray) => {
          return flatArray.concat(
            new UInt16BE(byteArray.length),
            new UInt8Array(byteArray)
          );
        },
        [new UInt8(sizeMask | array.length)]
      );
      this.byteLength = this.value.reduce(
        // eslint-disable-next-line @typescript-eslint/restrict-plus-operands
        (total, element) => total + element.byteLength,
        0
      );
    }
  };
};
var BOXSPEC = {
  // File Type Box
  ftyp: {
    container: "file",
    mandatory: true,
    quantity: "one",
    box: "Box",
    is_container: true,
    body: [
      ["major_brand", CharArray, "isom"],
      ["minor_version", UInt32BE, 0],
      ["compatible_brands", CharArray, "mp41"]
      // ['compatible_brands1', CharArray, 'iso2'],
      // ['compatible_brands2', CharArray, 'dash'],
    ]
  },
  // Movie Container
  moov: {
    container: "file",
    mandatory: true,
    quantity: "one",
    box: "Box",
    is_container: true
  },
  // Movie Data Box
  mdat: {
    container: "file",
    mandatory: false,
    quantity: "any",
    box: "Box",
    is_container: false,
    body: []
  },
  // Movie Header Box
  mvhd: {
    container: "moov",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["creation_time", UInt32BE, 0],
      ["modification_time", UInt32BE, 0],
      ["timescale", UInt32BE, 1e3],
      // time-scale for entire presentation, default = milliseconds
      ["duration", UInt32BE, 4294967295],
      // length of entire presentation, default = undetermined
      ["rate", UInt32BE, 65536],
      // fixed point 16.16, preferred playback rate, default = 1.0
      ["volume", UInt16BE, 256],
      // fixed point 8.8, preferred playback volume, default = 1.0
      ["reserved", Empty, 10],
      // transformation matrix, default = unity
      [
        "matrix",
        UInt32BEArray,
        [65536, 0, 0, 0, 65536, 0, 0, 0, 1073741824]
      ],
      ["pre_defined", Empty, 24],
      ["next_track_ID", UInt32BE, 4294967295]
      // next unused track ID, default = unknown
    ]
  },
  // Track Container
  trak: {
    container: "moov",
    mandatory: true,
    quantity: "one+",
    box: "Box",
    is_container: true
  },
  // Track Header Box
  tkhd: {
    container: "trak",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    // Flag values for the track header:
    // 0x000001 Track_enabled: track enabled (otherwise ignored)
    // 0x000002 Track_in_movie: track used in presentation
    // 0x000004 Track_in_preview: used when previewing presentation
    config: {
      flags: 3
      // track enabled and used in presentation
    },
    body: [
      ["creation_time", UInt32BE, 0],
      ["modification_time", UInt32BE, 0],
      ["track_ID", UInt32BE, 1],
      // Track identifier, cannot be 0
      ["reserved", Empty, 4],
      ["duration", UInt32BE, 0],
      // Duration of track using timescale of mvhd box
      ["reserved2", Empty, 8],
      ["layer", UInt16BE, 0],
      // Front-to-back ordering, lower is closer to viewer
      ["alternate_group", UInt16BE, 0],
      // Possible grouping of tracks
      ["volume", UInt16BE, 256],
      // Track's relative audio volume 8.8 fixed point
      ["reserved3", Empty, 2],
      [
        "matrix",
        UInt32BEArray,
        [65536, 0, 0, 0, 65536, 0, 0, 0, 1073741824]
      ],
      ["width", UInt32BE, 0],
      // Visual presentation width, 16.16 fixed point
      ["height", UInt32BE, 0]
      // Visual presentation height, 16.16 fixed point
    ]
  },
  // Track Reference Box
  tref: {
    container: "trak",
    mandatory: false,
    quantity: "one-",
    box: "Box",
    is_container: false
  },
  // Media Container
  mdia: {
    container: "trak",
    mandatory: false,
    quantity: "one",
    box: "Box",
    is_container: true
  },
  // Media Header Box
  mdhd: {
    container: "mdia",
    mandatory: false,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["creation_time", UInt32BE, 0],
      ["modification_time", UInt32BE, 0],
      ["timescale", UInt32BE, 1e3],
      // time-scale for entire presentation, default = milliseconds
      ["duration", UInt32BE, 4294967295],
      // length of entire presentation, default = undetermined
      ["language", UInt16BE, 0],
      // ISO 639-2 lanugage code, three lower-case letters, stored as
      ["pre_defined", UInt16BE, 0]
    ]
  },
  // Handler Reference Box
  hdlr: {
    container: "mdia",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["predefined", UInt32BE, 0],
      ["handler_type", CharArray, "vide"],
      // 'vide', 'soun', or 'hint'
      ["reserved", Empty, 12],
      ["name", CharArray, "VideoHandler\0"]
    ]
  },
  // Media Information Container
  minf: {
    container: "mdia",
    mandatory: true,
    quantity: "one",
    box: "Box",
    is_container: true
  },
  // Video Media Header Box
  vmhd: {
    container: "minf",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    config: {
      flags: 1
    },
    body: [
      ["graphicsmode", UInt16BE, 0],
      // Composition mode of the video track, 0 = overwrite
      ["opcolor", UInt16BEArray, [0, 0, 0]]
      // Red green blue, for use by graphics modes
    ]
  },
  // Sound Media Header Box
  smhd: {
    container: "minf",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      // Place mono track in stereo space:
      //  8.8 fixed point, 0 = center, -1.0 = left, 1.0 = right
      ["balance", UInt16BE, 0],
      ["reserved", UInt16BE]
    ]
  },
  // Data Information Container
  dinf: {
    container: "minf",
    mandatory: true,
    quantity: "one",
    box: "Box",
    is_container: true
  },
  // Data Reference Box
  dref: {
    // When adding elements to this box, update the entry_count value!
    container: "dinf",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: true,
    body: [
      ["entry_count", UInt32BE, 0]
      // Number of entries.
    ]
  },
  "url ": {
    container: "dref",
    mandatory: true,
    quantity: "one+",
    box: "FullBox",
    is_container: false,
    // Flag values:
    // 0x000001 Local reference, which means empty URL
    config: {
      flags: 1
    },
    body: [
      // ['location', CharArray, ''],
    ]
  },
  // Sample Table Container
  stbl: {
    container: "minf",
    mandatory: true,
    quantity: "one",
    box: "Box",
    is_container: true
  },
  // Decoding Time to Sample Box
  stts: {
    container: "stbl",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["entry_count", UInt32BE, 0]
      // For each entry these two elements:
      // ['sample_count', UInt32BE, 0], // Number of consecutive samples with same delta
      // ['sample_delta', UInt32BE, 0], // Delta of each sample
    ]
  },
  stsd: {
    container: "stbl",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: true,
    body: [
      ["entry_count", UInt32BE, 1]
      // For each entry, one of these three boxes depending on the handler:
      // VisualSampleEntry, AudioSampleEntry, HintSampleEntry
    ]
  },
  /*
  ISO/IEC 14496-12:2005(E) 8.16.2 (pp. 28)
  aligned(8) abstract class SampleEntry (unsigned int(32) format)
    extends Box(format){
    const unsigned int(8)[6] reserved = 0;
    unsigned int(16) data_reference_index;
  }
  class VisualSampleEntry(codingname) extends SampleEntry (codingname){
    unsigned int(16) pre_defined = 0;
    const unsigned int(16) reserved = 0;
    unsigned int(32)[3] pre_defined = 0;
    unsigned int(16) width;
    unsigned int(16) height;
    template unsigned int(32) horizresolution = 0x00480000; // 72 dpi
    template unsigned int(32) vertresolution = 0x00480000; // 72 dpi
    const unsigned int(32) reserved = 0;
    template unsigned int(16) frame_count = 1;
    string[32] compressorname;
    template unsigned int(16) depth = 0x0018;
    int(16) pre_defined = -1;
  }
  ISO/IEC 14496-15:2004(E) 5.3.4.1 (pp. 14)
  class AVCSampleEntry() extends VisualSampleEntry (‘avc1’){
    AVCConfigurationBox config;
    MPEG4BitRateBox (); // optional
    MPEG4ExtensionDescriptorsBox (); // optional
  }
  */
  avc1: {
    container: "stsd",
    mandatory: false,
    quantity: "one",
    box: "Box",
    is_container: true,
    body: [
      ["reserved", Empty, 6],
      ["data_reference_index", UInt16BE, 1],
      ["pre_defined", UInt16BE, 0],
      ["reserved2", Empty, 2],
      ["pre_defined2", UInt32BEArray, [0, 0, 0]],
      ["width", UInt16BE, 1920],
      ["height", UInt16BE, 1080],
      ["horizresolution", UInt32BE, 4718592],
      ["vertresolution", UInt32BE, 4718592],
      ["reserved3", UInt32BE, 0],
      ["frame_count", UInt16BE, 1],
      ["compressorname", UInt8Array, Buffer.alloc(32)],
      ["depth", UInt16BE, 24],
      ["pre_defined3", UInt16BE, 65535]
    ]
  },
  /*
  class AVCConfigurationBox extends Box(‘avcC’) {
    AVCDecoderConfigurationRecord() AVCConfig;
  }
  ISO/IEC 14496-15:2004(E) 5.2.4.1.1 (pp. 12)
  aligned(8) class AVCDecoderConfigurationRecord {
    unsigned int(8) configurationVersion = 1;
    unsigned int(8) AVCProfileIndication;
    unsigned int(8) profile_compatibility;
    unsigned int(8) AVCLevelIndication;
    bit(6) reserved = ‘111111’b;
    unsigned int(2) lengthSizeMinusOne;
    bit(3) reserved = ‘111’b;
    unsigned int(5) numOfSequenceParameterSets;
    for (i=0; i< numOfSequenceParameterSets; i++) {
      unsigned int(16) sequenceParameterSetLength ;
      bit(8*sequenceParameterSetLength) sequenceParameterSetNALUnit;
    }
    unsigned int(8) numOfPictureParameterSets;
    for (i=0; i< numOfPictureParameterSets; i++) {
      unsigned int(16) pictureParameterSetLength;
      bit(8*pictureParameterSetLength) pictureParameterSetNALUnit;
    }
  }
  */
  avcC: {
    container: "avc1",
    mandatory: false,
    quantity: "one",
    box: "Box",
    is_container: false,
    body: [
      ["configurationVersion", UInt8, 1],
      ["AVCProfileIndication", UInt8, 77],
      ["profile_compatibility", UInt8, 0],
      ["AVCLevelIndication", UInt8, 41],
      // size = reserved 0b111111 + 0b11 NALUnitLength (0b11 = 4-byte)
      ["lengthSizeMinusOne", UInt8, 255],
      // Example SPS (length 20):
      //   [0x67, 0x4d, 0x00, 0x29, 0xe2, 0x90, 0x0f, 0x00,
      //    0x44, 0xfc, 0xb8, 0x0b, 0x70, 0x10, 0x10, 0x1a,
      //    0x41, 0xe2, 0x44, 0x54]
      // number of sets = reserved 0b111 + number of SPS (0b00001 = 1)
      // ['numOfSequenceParameterSets', UInt8, 0b11100001],
      // ['sequenceParameterSetLength', UInt16BE, 0], // Lenght in bytes of the SPS that follows
      // ['sequenceParameterSetNALUnit', UInt8Array, []],
      // These are packed in a single custom element:
      ["sequenceParameterSets", createParameterSetArrayClass(224), []],
      // Example PPS (length 4):
      //   [0x68, 0xee, 0x3c, 0x80]
      // ['numOfPictureParameterSets', UInt8, 1], // number of PPS
      // ['pictureParameterSetLength', UInt16BE, 0], // Length in bytes of the PPS that follows
      // ['pictureParameterSetNALUnit', UInt8Array, []]
      // These are packed in a single custom element:
      ["pictureParameterSets", createParameterSetArrayClass(), []]
    ]
  },
  /*
  ISO/IEC 14496-12:2005(E) 8.16.2 (pp. 28)
  aligned(8) abstract class SampleEntry (unsigned int(32) format)
    extends Box(format){
    const unsigned int(8)[6] reserved = 0;
    unsigned int(16) data_reference_index;
  }
  class AudioSampleEntry(codingname) extends SampleEntry (codingname){
    const unsigned int(32)[2] reserved = 0;
    template unsigned int(16) channelcount = 2;
    template unsigned int(16) samplesize = 16;
    unsigned int(16) pre_defined = 0;
    const unsigned int(16) reserved = 0 ;
    template unsigned int(32) samplerate = {timescale of media}<<16;
  }
  */
  mp4a: {
    container: "stsd",
    mandatory: false,
    quantity: "one",
    box: "Box",
    is_container: true,
    body: [
      ["reserved", Empty, 6],
      ["data_reference_index", UInt16BE, 1],
      ["reserved2", UInt32BEArray, [0, 0]],
      ["channelcount", UInt16BE, 2],
      ["samplesize", UInt16BE, 16],
      ["pre_defined", UInt16BE, 0],
      ["reserved3", UInt16BE, 0],
      ["samplerate", UInt32BE, 0]
      // 16.16 bit floating point
    ]
  },
  /* Elementary stream descriptor
    basic box that holds only an ESDescriptor
    reference: 'https://developer.apple.com/library/content/documentation/QuickTime/
  QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-124774'
    Descriptors have a tag that identifies them, specified in ISO/IEC 14496-1 8.3.12
    ISO/IEC 14496-1 8.3.3 (pp. 24) ES_Descriptor
    aligned(8) class ES_Descriptor : bit(8) tag=ES_DescrTag {
      bit(8) length;
      bit(16) ES_ID;
      bit(1) streamDependenceFlag;
      bit(1) URL_Flag;
      const bit(1) reserved=1;
      bit(5) streamPriority;
      if (streamDependenceFlag)
        bit(16) dependsOn_ES_ID;
      if (URL_Flag)
        bit(8) URLstring[length-3-(streamDependencFlag*2)];
      ExtensionDescriptor extDescr[0 .. 255];
      LanguageDescriptor langDescr[0 .. 1];
      DecoderConfigDescriptor decConfigDescr;
      SLConfigDescriptor slConfigDescr;
      IPI_DescPointer ipiPtr[0 .. 1];
      IP_IdentificationDataSet ipIDS[0 .. 1];
      QoS_Descriptor qosDescr[0 .. 1];
    }
    aligned(8) class DecoderConfigDescriptor
      : bit(8) tag=DecoderConfigDescrTag {
      bit(8) length;
      bit(8) objectProfileIndication;
      bit(6) streamType;
      bit(1) upStream;
      const bit(1) reserved=1;
      bit(24) bufferSizeDB;
      bit(32) maxBitrate;
      bit(32) avgBitrate;
      DecoderSpecificInfo decSpecificInfo[];
    }
    aligned(8) class DecoderSpecificInfoShort extends DecoderSpecificInfo
    : bit(8) tag=DecSpecificInfoShortTag
    {
      bit(8) length;
      bit(8) specificInfo[length];
    }
    aligned(8) class SLConfigDescriptor : bit(8) tag=SLConfigDescrTag {
      bit(8) length;
      bit(8) predefined;
      if (predefined==0) {
        bit(1) useAccessUnitStartFlag;
        bit(1) useAccessUnitEndFlag;
        bit(1) useRandomAccessPointFlag;
        bit(1) usePaddingFlag;
        bit(1) useTimeStampsFlag;
        bit(1) useWallClockTimeStampFlag;
        bit(1) useIdleFlag;
        bit(1) durationFlag;
        bit(32) timeStampResolution;
        bit(32) OCRResolution;
        bit(8) timeStampLength; // must be less than 64
        bit(8) OCRLength;
        // must be less than 64
        bit(8) AU_Length;
        // must be less than 32
        bit(8) instantBitrateLength;
        bit(4) degradationPriorityLength;
        bit(4) seqNumLength;
        if (durationFlag) {
          bit(32) timeScale;
          bit(16) accessUnitDuration;
          bit(16) compositionUnitDuration;
        }
        if (!useTimeStampsFlag) {
          if (useWallClockTimeStampFlag)
            double(64) wallClockTimeStamp;
          bit(timeStampLength) startDecodingTimeStamp;
          bit(timeStampLength) startCompositionTimeStamp;
        }
      }
      aligned(8) bit(1) OCRstreamFlag;
      const bit(7) reserved=0b1111.111;
      if (OCRstreamFlag)
        bit(16) OCR_ES_Id;
    }
    */
  esds: {
    container: "mp4a",
    mandatory: false,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["ES_DescrTag", UInt8, 3],
      // length of the remainder of this descriptor in byte,
      // excluding trailing embedded descriptors.
      ["ES_DescrLength", UInt8, 25],
      ["ES_ID", UInt16BE, 1],
      ["flagsAndStreamPriority", UInt8, 0],
      ["DecoderConfigDescrTag", UInt8, 4],
      // length of the remainder of this descriptor in bytes,
      // excluding trailing embedded descriptors.
      ["DecoderConfigDescrLength", UInt8, 17],
      ["objectProfileIndication", UInt8, 64],
      ["streamTypeUpstreamReserved", UInt8, 21],
      ["bufferSizeDB", UInt8Array, [0, 0, 0]],
      ["maxBitRate", UInt32BE, 0],
      ["avgBitRate", UInt32BE, 0],
      ["DecSpecificInfoShortTag", UInt8, 5],
      ["DecSpecificInfoShortLength", UInt8, 2],
      ["audioConfigBytes", UInt16BE, 0],
      ["SLConfigDescrTag", UInt8, 6],
      ["SLConfigDescrLength", UInt8, 1],
      ["SLConfigDescrPredefined", UInt8, 2]
      // ISO use
    ]
  },
  // Sample Size Box
  stsz: {
    container: "stbl",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["sample_size", UInt32BE, 0],
      ["sample_count", UInt32BE, 0]
      // For each sample up to sample_count, append an entry_size:
      // ['entry_size', UInt32BE, ],
    ]
  },
  // Sample To Chunk Box
  stsc: {
    container: "stbl",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["entry_count", UInt32BE, 0]
      // For each entry up to entry_count, append these elements:
      // ['first_chunk', UInt32BE, ],
      // ['samples_per_chunk', UInt32BE, ],
      // ['samples_description_index', UInt32BE, ],
    ]
  },
  // Chunk Offset Box
  stco: {
    container: "stbl",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["entry_count", UInt32BE, 0]
      // For each entry up to entry_count, append an element:
      // ['chunk_offset', UInt32BE, ],
    ]
  },
  // Sync Sample Box
  stss: {
    container: "stbl",
    mandatory: false,
    quantity: "one-",
    box: "FullBox",
    is_container: false,
    body: [
      ["entry_count", UInt32BE, 0]
      // For each entry up to entry_count, append an element:
      // ['sample_number', UInt32BE, ],
    ]
  },
  // Edit Box
  edts: {
    container: "trak",
    mandatory: false,
    quantity: "one-",
    box: "Box",
    is_container: true
  },
  // Edit List Box
  elst: {
    container: "edts",
    mandatory: false,
    quantity: "one-",
    box: "FullBox",
    is_container: false,
    body: [
      ["entry_count", UInt32BE, 1],
      ["segment_duration", UInt32BE, 0],
      ["media_time", UInt32BE, 4294967295],
      ["media_rate_integer", UInt16BE, 1],
      ["media_rate_fraction", UInt16BE, 0]
    ]
  },
  mvex: {
    container: "moov",
    mandatory: false,
    quantity: "one-",
    box: "Box",
    is_container: true
  },
  mehd: {
    container: "mvex",
    mandatory: false,
    quantity: "one-",
    box: "FullBox",
    is_container: false,
    body: [
      ["fragment_duration", UInt32BE, 0]
      // Total duration of movie
    ]
  },
  trex: {
    container: "mvex",
    mandatory: true,
    quantity: "one+",
    box: "FullBox",
    is_container: false,
    body: [
      ["track_ID", UInt32BE, 1],
      // The track to which this data is applicable
      ["default_sample_description_index", UInt32BE, 1],
      ["default_sample_duration", UInt32BE, 0],
      ["default_sample_size", UInt32BE, 0],
      ["default_sample_flags", UInt32BE, 0]
    ]
  },
  moof: {
    container: "file",
    mandatory: false,
    quantity: "zero+",
    box: "Box",
    is_container: false
  },
  mfhd: {
    container: "moof",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    body: [
      ["sequence_number", UInt32BE, 0]
      // A number associated with this fragment
    ]
  },
  traf: {
    container: "moof",
    mandatory: false,
    quantity: "zero+",
    box: "Box",
    is_container: true
  },
  tfhd: {
    container: "traf",
    mandatory: true,
    quantity: "one",
    box: "FullBox",
    is_container: false,
    // Flag values for the track fragment header:
    // 0x000001 base-data-offset-present
    // 0x000002 sample-description-index-present
    // 0x000008 default-sample-duration-present
    // 0x000010 default-sample-size-present
    // 0x000020 default-sample-flags-present
    // 0x010000 duration-is-empty
    // 0x020000 default-base-is-moof
    config: {
      flags: 32
      // default sample flags present
    },
    body: [
      ["track_ID", UInt32BE, 1],
      // The track to which this data is applicable
      // ['base_data_offset', UInt64BE, 0],
      // ['default_sample_description_index', UInt32BE, 0],
      // ['default_sample_duration', UInt32BE, 0],
      // ['default_sample_size', UInt32BE, 0],
      ["default_sample_flags", UInt32BE, 0]
    ]
  },
  tfdt: {
    container: "traf",
    mandatory: false,
    quantity: "one-",
    box: "FullBox",
    is_container: false,
    config: {
      version: 1
      // Version 1 uses 64-bit value for baseMediaDecodeTime
    },
    body: [["baseMediaDecodeTime", UInt64BE, 0]]
  },
  trun: {
    container: "traf",
    mandatory: false,
    quantity: "zero+",
    box: "FullBox",
    is_container: false,
    // Flag values for the track fragment header:
    // 0x000001 data-offset-present
    // 0x000004 first-sample-flags-present
    // 0x000100 sample-duration-present
    // 0x000200 sample-size-present
    // 0x000400 sample-flags-present
    // 0x000800 sample-composition-time-offsets-present
    config: {
      flags: 773
      // default sample flags present
    },
    body: [
      ["sample_count", UInt32BE, 1],
      // How many samples there are
      ["data_offset", UInt32BE, 0],
      ["first_sample_flags", UInt32BE, 0],
      ["sample_duration", UInt32BE, 0],
      ["sample_size", UInt32BE, 0]
      // ['sample_flags', UInt32BE, 0],
      // ['sample_composition_time_offset', UInt32BE, 0],
    ]
  },
  // Unknown Box, used for parsing
  "....": {
    box: "Box",
    is_container: false,
    body: []
  },
  // File Box, special box without any headers
  file: {
    box: "None",
    is_container: true,
    mandatory: true,
    quantity: "one"
  }
};
var Header = class {
  static None() {
    return [];
  }
  static Box(type) {
    return [
      ["size", UInt32BE, 0],
      ["type", CharArray, type]
    ];
  }
  static FullBox(type) {
    return [].concat(this.Box(type), [
      ["version", UInt8, 0],
      ["flags", UInt24BE, 0]
    ]);
  }
};
var Box = class extends BoxElement {
  /**
   * Create a new Box.
   * @param  type   4-character ASCII string
   * @param  config Configuration holding (key: value) fields
   */
  constructor(type, config) {
    super(0);
    __publicField(this, "type");
    __publicField(this, "config");
    __publicField(this, "struct");
    this.type = type;
    const spec = BOXSPEC[this.type];
    if (spec === void 0) {
      throw new Error(`unknown box type: ${type}`);
    }
    this.config = Object.assign({}, spec.config, config);
    const header = Header[spec.box](this.type);
    const body = spec.body || [];
    this.struct = /* @__PURE__ */ new Map();
    let offset = 0;
    for (const [key, Type, defaultValue] of [].concat(header, body)) {
      if (this.has(key)) {
        throw new Error("Trying to add existing key");
      }
      let value = defaultValue;
      if (this.config[key]) {
        value = this.config[key];
      }
      const element = new Type(value);
      this.struct.set(key, { offset, element });
      offset += element.byteLength;
    }
    this.byteLength = offset;
  }
  /**
   * Get access to an element based on it's name.
   * @param  key The element's name
   * @return Object with 'byteLength' property and 'copy' method
   */
  element(key) {
    const value = this.struct.get(key);
    if (value === void 0) {
      throw new Error("invalid key");
    }
    return value.element;
  }
  /**
   * Set an element's value.
   * @param  key The element's name
   * @param  value The element's (new) value
   */
  set(key, value) {
    this.element(key).value = value;
  }
  /**
   * Get an element's value.
   * @param  key The element's name
   * @return The element's value
   */
  get(key) {
    return this.element(key).value;
  }
  /**
   * Get an element's offset.
   * @param  key The element's name
   * @return The element's offset
   */
  offset(key) {
    const value = this.struct.get(key);
    if (value === void 0) {
      throw new Error("invalid key");
    }
    return value.offset;
  }
  /**
   * Check if a certain element exists
   * @param  key The element's name
   * @return true if the element is known, false if not
   */
  has(key) {
    return this.struct.has(key);
  }
  /**
   * Add a new element to the box.
   * @param key     A _new_ non-existing element name.
   * @param element Something with a 'byteLength' property and 'copy' method.
   * @return this box, so that 'add' can be used in a chain
   */
  add(key, element) {
    if (this.has(key)) {
      throw new Error("Trying to add existing key");
    }
    this.struct.set(key, { offset: this.byteLength, element });
    this.byteLength += element.byteLength;
    return this;
  }
  /**
   * Create a buffer and copy all element values to it.
   * @return Data representing the box.
   */
  buffer() {
    const buffer = Buffer.allocUnsafe(this.byteLength);
    this.copy(buffer);
    return buffer;
  }
  /**
   * Copy all values of the box into an existing buffer.
   * @param  buffer     The target buffer to accept the box data
   * @param  [offset=0] The number of bytes into the target to start at.
   */
  copy(buffer, offset = 0) {
    this.set("size", this.byteLength);
    for (const entry of this.struct.values()) {
      entry.element.copy(buffer, offset + entry.offset);
    }
  }
  /**
   * Read element values from a box's data representation.
   * @param  buffer     The source buffer with box data
   * @param  [offset=0] The number of bytes into the source to start at.
   */
  load(buffer, offset = 0) {
    for (const entry of this.struct.values()) {
      if (entry.element.load !== void 0) {
        entry.element.load(buffer, offset + entry.offset);
      }
    }
  }
  /**
   * Pretty-format an entire box as an element/box hierarchy.
   * @param  [indent=0] How large an indentation to use for the hierarchy
   */
  format(indent = 0) {
    const lines = [`${" ".repeat(indent)}[${this.type}] (${this.byteLength})`];
    for (const [key, entry] of this.struct) {
      const element = entry.element;
      if (element.format !== void 0) {
        lines.push(element.format(indent + 2));
      } else {
        lines.push(
          `${" ".repeat(indent + 2)}${key} = ${element.value} (${element.byteLength})`
        );
      }
    }
    return lines.join("\n");
  }
  /**
   * Pretty-print an entire box as an element/box hierarchy.
   * @param  [indent=0] How large an indentation to use for the hierarchy
   */
  print(indent) {
    console.warn(this.format(indent));
  }
};
var Container = class _Container extends Box {
  /**
   * Create a new container box
   * @param  type   4-character ASCII string
   * @param  config Configuration holding (key: value) fields
   * @param  boxes  One or more boxes to append.
   */
  constructor(type, config, ...boxes) {
    super(type, config);
    __publicField(this, "boxSize");
    this.boxSize = 0;
    this.append(...boxes);
  }
  /**
   * Add one or more boxes to the container.
   * @param boxes The box(es) to append
   * @return this container, so that add can be used in a chain
   */
  append(...boxes) {
    for (const box of boxes) {
      this.add(`box_${this.boxSize++}`, box);
    }
    return this;
  }
  /**
   * Parse a container box by looking for boxes that it contains, and
   * recursively proceed when it is another container.
   *
   * FIXME: this cannot properly handle different versions of the FullBox,
   * currenlty the loader is hardcoded to the version used in this file.
   * Also, appearance of an esds box is assumed to be AAC audio information,
   * while the avcC box signals H.264 video information.
   *
   * @param  data The data to parse.
   */
  parse(data) {
    const tracks = [];
    while (data.byteLength > 0) {
      const type = new CharArray("....");
      type.load(data, 4);
      const boxType = type.value;
      const spec = BOXSPEC[boxType];
      let box;
      if (spec !== void 0) {
        if (spec.is_container) {
          box = new _Container(boxType);
          box.load(data);
          const boxTracks = box.parse(
            data.slice(box.byteLength, box.get("size"))
          );
          tracks.push(...boxTracks);
        } else {
          box = new Box(boxType);
          box.load(data);
          if (boxType === "avcC") {
            const profile = box.element("AVCProfileIndication").value.toString(16).padStart(2, 0);
            const compat = box.element("profile_compatibility").value.toString(16).padStart(2, 0);
            const level = box.element("AVCLevelIndication").value.toString(16).padStart(2, 0);
            tracks.push({
              type: "video",
              mime: `avc1.${profile}${compat}${level}`
            });
          } else if (boxType === "esds") {
            const audioConfigBytes = box.element("audioConfigBytes").value;
            const objectTypeIndication = audioConfigBytes >>> 11 & 31;
            tracks.push({
              type: "audio",
              mime: `mp4a.40.${objectTypeIndication}`
            });
          }
        }
      } else {
        box = new Box("....");
        box.load(data);
        box.type = box.get("type");
      }
      this.append(box);
      data = data.slice(box.get("size"));
    }
    return tracks;
  }
};

// src/components/mp4muxer/helpers/aacSettings.ts
var AUDIO_OBJECT_TYPE_NAMES = {
  1: "AAC Main",
  2: "AAC LC"
};
var FREQUENCY_VALUES = {
  0: "96 kHz",
  1: "88.2 kHz",
  2: "64 kHz",
  3: "48 kHz",
  4: "44.1 kHz",
  5: "32 kHz",
  6: "24 kHz",
  7: "22.05 kHz",
  8: "16 kHz",
  9: "12 kHz",
  10: "11.025 kHz",
  11: "8 kHz",
  12: "7.35 kHz"
};
var CHANNEL_CONFIG_NAMES = {
  1: "Mono",
  2: "Stereo"
};
var aacEncodingName = (audioConfigBytes) => {
  const audioObjectType = audioConfigBytes >>> 11 & 31;
  const frequencyIndex = audioConfigBytes >>> 7 & 15;
  const channelConfig = audioConfigBytes >>> 3 & 15;
  const audioType = AUDIO_OBJECT_TYPE_NAMES[audioObjectType] || `AAC (${audioObjectType})`;
  const samplingRate = FREQUENCY_VALUES[frequencyIndex] || "unknown";
  const channels = CHANNEL_CONFIG_NAMES[channelConfig] || channelConfig.toString();
  return {
    coding: audioType,
    samplingRate,
    channels
  };
};
var aacSettings = (media, date, trackId) => {
  const bitrate = Number(media.fmtp.parameters.bitrate) || 32e4;
  const audioConfigBytes = parseInt(media.fmtp.parameters.config, 16);
  const audioObjectType = audioConfigBytes >>> 11 & 31;
  return {
    tkhd: {
      track_ID: trackId,
      creation_time: date,
      modification_time: date,
      width: 0,
      height: 0,
      volume: 1
    },
    mdhd: {
      timescale: Number(media.rtpmap.clockrate),
      creation_time: date,
      modification_time: date,
      duration: 0
    },
    hdlr: {
      handler_type: "soun",
      name: "SoundHandler\0"
      // 00 soundhandler, add 00 if things screws up
    },
    mediaHeaderBox: new Box("smhd"),
    sampleEntryBox: new Container(
      "mp4a",
      {
        samplerate: media.rtpmap.clockrate << 16 >>> 0
        // FIXME: Is this  correct?
      },
      new Box("esds", {
        audioConfigBytes,
        // Converting from hex string to int
        maxBitRate: bitrate,
        avgBitRate: bitrate
      })
    ),
    /*
    https://wiki.multimedia.cx/index.php/Understanding_AAC
    AAC is a variable bitrate (VBR) block-based codec where each block decodes
    to 1024 time-domain samples, which means that a single block (or frame?) is
    1024 ticks long, which we take as default here.
    */
    defaultFrameDuration: 1024,
    // MIME type
    mime: `mp4a.40.${audioObjectType}`,
    codec: aacEncodingName(audioConfigBytes)
  };
};

// src/components/mp4muxer/helpers/bufferreader.ts
var BufferReader = class {
  constructor(buffer) {
    __publicField(this, "_buffer");
    __publicField(this, "_dataView");
    __publicField(this, "_offset");
    __publicField(this, "_bitpos");
    __publicField(this, "_byte");
    this._buffer = buffer;
    this._dataView = new DataView(this._buffer);
    this._offset = 0;
    this._bitpos = 0;
    this._byte = 0;
  }
  /**
   * Reads 8-bit of data from the buffer.
   * @method readUint8
   * @param  offset - Index in the buffer.
   * @return An unsigned 8-bit integer.
   */
  readUint8(offset) {
    return this._dataView.getUint8(offset);
  }
  /**
   * Reads 16-bit of data from the buffer.
   * @method readUint16
   * @param  offset - Index in the buffer.
   * @return An unsigned 16-bit integer.
   */
  readUint16(offset) {
    return this._dataView.getUint16(offset);
  }
  /**
   * Reads 32-bit of data from the buffer.
   * @method readUint32
   * @param  offset - Index in the buffer.
   * @return An unsigned 32-bit integer.
   */
  readUint32(offset) {
    return this._dataView.getUint32(offset);
  }
  /**
   * Reads the next byte of data from the buffer and increaments the offset.
   * @method readNext
   * @return {Number} An unsigned 8-bit integer.
   */
  readNext() {
    const value = this.readUint8(this._offset);
    this._offset += 1;
    return value;
  }
  readBits(length) {
    if (length > 32 || length === 0) {
      throw new Error("length has to be between 0 - 31 bits");
    }
    let result = 0;
    for (let i = 1; i <= length; ++i) {
      if (this._bitpos === 0) {
        this._byte = this.readNext();
      }
      result = result << 1 | this._byte >> 8 - ++this._bitpos & 1;
      this._bitpos %= 8;
    }
    return result;
  }
  readUnsignedExpGolomb() {
    let bitsToRead = 0;
    while (this.readBits(1) !== 1) {
      bitsToRead++;
    }
    if (bitsToRead === 0) {
      return 0;
    }
    if (bitsToRead >= 31) {
      throw new Error("read unsigned exponential Golomb: internal error");
    }
    let n = this.readBits(bitsToRead);
    n |= 1 << bitsToRead;
    return n - 1;
  }
  readSignedExpGolomb() {
    let r = this.readUnsignedExpGolomb();
    if (r & 1) {
      r = r + 1 >> 1;
    } else {
      r = -(r >> 1);
    }
    return r;
  }
  /**
   * Returns the size of the buffer
   * @method readSize
   * @return {Number} The buffer size.
   */
  size() {
    return this._buffer.byteLength;
  }
  /**
   * Returns an instance of the buffer as an unsigned 8-bit integer array.
   * @method getUint8Array
   * @return {Uint8Array} Unsigned 8-bit integer representation of the buffer
   */
  getUint8Array() {
    return new Uint8Array(this._buffer);
  }
  /**
   * Returns the buffer object
   * @method getArrayBuffer
   * @return {ArrayBuffer} The buffer used the BufferReader
   */
  getArrayBuffer() {
    return this._buffer;
  }
};

// src/components/mp4muxer/helpers/spsparser.ts
var SPSParser = class {
  constructor(buffer) {
    __publicField(this, "reader");
    this.reader = new BufferReader(buffer);
  }
  parse() {
    this.reader.readNext();
    const profile = this.reader.readNext();
    this.reader.readNext();
    const level = this.reader.readNext();
    this.reader.readUnsignedExpGolomb();
    if ([100, 110, 122, 244, 44, 83, 86, 118].includes(profile)) {
      const chromaFormat = this.reader.readUnsignedExpGolomb();
      if (chromaFormat === 3) {
        this.reader.readBits(1);
      }
      this.reader.readUnsignedExpGolomb();
      this.reader.readUnsignedExpGolomb();
      this.reader.readBits(1);
      const seqScalingMatrix = this.reader.readBits(1);
      if (seqScalingMatrix) {
        for (let k = 0; k < (chromaFormat !== 3 ? 8 : 12); k++) {
          this.reader.readBits(1);
        }
      }
    }
    this.reader.readUnsignedExpGolomb();
    const picOrderCntType = this.reader.readUnsignedExpGolomb();
    if (picOrderCntType === 0) {
      this.reader.readUnsignedExpGolomb();
    } else if (picOrderCntType === 1) {
      let numRefFramesInPic = 0;
      this.reader.readBits(1);
      this.reader.readSignedExpGolomb();
      this.reader.readSignedExpGolomb();
      numRefFramesInPic = this.reader.readUnsignedExpGolomb();
      for (let i = 0; i < numRefFramesInPic; i++) {
        this.reader.readSignedExpGolomb();
      }
    }
    this.reader.readUnsignedExpGolomb();
    this.reader.readBits(1);
    const picWidthInMbsMinus1 = this.reader.readUnsignedExpGolomb();
    const picHeightInMapUnitsMinus1 = this.reader.readUnsignedExpGolomb();
    const picFrameMbsOnlyFlag = this.reader.readBits(1);
    this.reader.readBits(1);
    const frameCroppingFlag = this.reader.readBits(1);
    const frameCropLeftOffset = frameCroppingFlag ? this.reader.readUnsignedExpGolomb() : 0;
    const frameCropRightOffset = frameCroppingFlag ? this.reader.readUnsignedExpGolomb() : 0;
    const frameCropTopOffset = frameCroppingFlag ? this.reader.readUnsignedExpGolomb() : 0;
    const frameCropBottomOffset = frameCroppingFlag ? this.reader.readUnsignedExpGolomb() : 0;
    const w = (picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2;
    const h = (2 - picFrameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - frameCropTopOffset * 2 - frameCropBottomOffset * 2;
    return {
      profile,
      level: level / 10,
      width: w,
      height: h
    };
  }
};

// src/components/mp4muxer/helpers/utils.ts
function b64ToUint6(nChr) {
  return nChr > 64 && nChr < 91 ? nChr - 65 : nChr > 96 && nChr < 123 ? nChr - 71 : nChr > 47 && nChr < 58 ? nChr + 4 : nChr === 43 ? 62 : nChr === 47 ? 63 : 0;
}
function base64DecToArr(sBase64, nBlocksSize) {
  const sB64Enc = sBase64.replace(/[^A-Za-z0-9+/]/g, "");
  const nInLen = sB64Enc.length;
  const nOutLen = nBlocksSize ? Math.ceil((nInLen * 3 + 1 >> 2) / nBlocksSize) * nBlocksSize : nInLen * 3 + 1 >> 2;
  const taBytes = new Uint8Array(nOutLen);
  let nMod3;
  let nMod4;
  let nUint24 = 0;
  let nOutIdx = 0;
  for (let nInIdx = 0; nInIdx < nInLen; nInIdx++) {
    nMod4 = nInIdx & 3;
    nUint24 |= b64ToUint6(sB64Enc.charCodeAt(nInIdx)) << 18 - 6 * nMod4;
    if (nMod4 === 3 || nInLen - nInIdx === 1) {
      for (nMod3 = 0; nMod3 < 3 && nOutIdx < nOutLen; nMod3++, nOutIdx++) {
        taBytes[nOutIdx] = nUint24 >>> (16 >>> nMod3 & 24) & 255;
      }
      nUint24 = 0;
    }
  }
  return taBytes;
}

// src/components/mp4muxer/helpers/h264Settings.ts
var PROFILE_NAMES = {
  66: "Baseline",
  77: "Main",
  100: "High"
};
var h264EncodingName = (profileLevelId) => {
  const profileCode = parseInt(profileLevelId.substr(0, 2), 16);
  const levelCode = parseInt(profileLevelId.substr(4, 2), 16);
  const profile = PROFILE_NAMES[profileCode] || profileCode.toString();
  const level = (levelCode / 10).toFixed(1);
  return {
    coding: "H.264",
    profile,
    level
  };
};
var h264Settings = (media, date, trackId) => {
  const profileLevelId = media.fmtp.parameters["profile-level-id"];
  const parameterSets = media.fmtp.parameters["sprop-parameter-sets"].split(",").map(base64DecToArr);
  const sps = parameterSets.slice(0, 1);
  const pps = parameterSets.slice(1);
  const parsedSps = new SPSParser(sps[0].buffer).parse();
  const FALLBACK_FRAME_DURATION = 3600;
  return {
    mediaHeaderBox: new Box("vmhd"),
    sampleEntryBox: new Container(
      "avc1",
      {
        width: parsedSps.width,
        height: parsedSps.height
      },
      new Box("avcC", {
        AVCProfileIndication: sps[0][1],
        profile_compatibility: sps[0][2],
        AVCLevelIndication: sps[0][3],
        sequenceParameterSets: sps,
        pictureParameterSets: pps
      })
    ),
    tkhd: {
      track_ID: trackId,
      creation_time: date,
      modification_time: date,
      width: parsedSps.width << 16,
      height: parsedSps.height << 16,
      volume: 0
    },
    hdlr: {},
    mdhd: {
      timescale: media.rtpmap.clockrate,
      creation_time: date,
      modification_time: date,
      duration: 0
    },
    // (ticks / s) / (frames / s) = ticks / frame, e.g. frame duration in ticks
    defaultFrameDuration: media.framerate !== void 0 && media.framerate > 0 ? Number(media.rtpmap.clockrate) / Number(media.framerate) || FALLBACK_FRAME_DURATION : FALLBACK_FRAME_DURATION,
    // MIME type
    mime: `avc1.${profileLevelId}`,
    codec: h264EncodingName(profileLevelId)
  };
};

// src/components/mp4muxer/helpers/boxbuilder.ts
var formatDefaults = {
  "MPEG4-GENERIC": aacSettings,
  H264: h264Settings
};
var createTrackData = () => {
  return {
    lastTimestamp: 0,
    baseMediaDecodeTime: 0,
    defaultFrameDuration: 0,
    clockrate: 0,
    bitrate: 0,
    framerate: 0,
    cumulativeByteLength: 0,
    cumulativeDuration: 0,
    cumulativeFrames: 0
  };
};
var updateRateInfo = (trackData, { byteLength, duration }) => {
  trackData.cumulativeByteLength += byteLength;
  trackData.cumulativeDuration += duration;
  trackData.cumulativeFrames++;
  if (trackData.cumulativeDuration >= trackData.clockrate) {
    const bits = 8 * trackData.cumulativeByteLength;
    const frames = trackData.cumulativeFrames;
    const seconds = trackData.cumulativeDuration / trackData.clockrate;
    trackData.bitrate = bits / seconds;
    trackData.framerate = frames / seconds;
    trackData.cumulativeByteLength = 0;
    trackData.cumulativeDuration = 0;
    trackData.cumulativeFrames = 0;
  }
};
var BoxBuilder = class {
  constructor() {
    __publicField(this, "trackIdMap");
    __publicField(this, "sequenceNumber");
    __publicField(this, "ntpPresentationTime");
    __publicField(this, "trackData");
    __publicField(this, "videoTrackId");
    this.trackIdMap = {};
    this.sequenceNumber = 0;
    this.ntpPresentationTime = 0;
    this.trackData = [];
  }
  trak(settings) {
    const trak = new Container("trak");
    const mdia = new Container("mdia");
    const minf = new Container("minf");
    const dinf = new Container("dinf");
    const dref = new Container("dref");
    const stbl = new Container("stbl");
    dref.set("entry_count", 1);
    trak.append(
      new Box("tkhd", settings.tkhd),
      mdia.append(
        new Box("mdhd", settings.mdhd),
        new Box("hdlr", settings.hdlr),
        minf.append(
          settings.mediaHeaderBox,
          // vmhd or smhd box (video or sound)
          dinf.append(dref.append(new Box("url "))),
          stbl.append(
            new Container("stsd", void 0, settings.sampleEntryBox),
            new Box("stts"),
            new Box("stsc"),
            new Box("stco"),
            new Box("stsz"),
            new Box("stss")
          )
        )
      )
    );
    return trak;
  }
  /**
   * Creates a Moov box from the provided options.
   * @method moov
   * @param  sdp - The session description protocol
   * @param  date - The creation/modification time of the movie
   * @return Moov object
   */
  moov(sdp, date) {
    const moov = new Container("moov");
    moov.append(
      new Box("mvhd", {
        creation_time: date,
        modification_time: date,
        duration: 0
      })
    );
    const mvex = new Container("mvex");
    this.trackIdMap = {};
    this.sequenceNumber = 0;
    this.ntpPresentationTime = 0;
    let trackId = 0;
    this.trackData = [];
    sdp.media.forEach((media) => {
      if (media.rtpmap === void 0) {
        return;
      }
      const payloadType2 = media.rtpmap.payloadType;
      const encoding = media.rtpmap.encodingName;
      if (formatDefaults[encoding] !== void 0) {
        this.trackIdMap[payloadType2] = ++trackId;
        if (media.type.toLowerCase() === "video") {
          this.videoTrackId = trackId;
        }
        const settings = formatDefaults[encoding](media, date, trackId);
        media.mime = settings.mime;
        media.codec = settings.codec;
        const trackData = createTrackData();
        trackData.clockrate = media.rtpmap.clockrate;
        trackData.defaultFrameDuration = settings.defaultFrameDuration;
        this.trackData.push(trackData);
        const trak = this.trak(settings);
        moov.append(trak);
        mvex.append(new Box("trex", { track_ID: trackId }));
      }
    });
    moov.append(mvex);
    return moov;
  }
  /**
   * Boxes that carry actual elementary stream fragment metadata + data.
   */
  /**
   * Creates a moof box from the provided fragment metadata.
   * @method moof
   * @param  metadata - Track ID, timestamp, bytelength
   * @return moof Container
   */
  moof(metadata) {
    const { trackId, timestamp: timestamp2, byteLength } = metadata;
    const trackOffset = trackId - 1;
    const trackData = this.trackData[trackOffset];
    const duration = trackData.lastTimestamp !== 0 ? timestamp2 - trackData.lastTimestamp | 0 : trackData.defaultFrameDuration;
    trackData.lastTimestamp = timestamp2;
    const moof = new Container("moof");
    const traf = new Container("traf");
    const trun = new Box("trun", {
      sample_duration: duration,
      sample_size: byteLength,
      first_sample_flags: 64
    });
    moof.append(
      new Box("mfhd", { sequence_number: this.sequenceNumber++ }),
      traf.append(
        new Box("tfhd", { track_ID: trackId }),
        new Box("tfdt", { baseMediaDecodeTime: trackData.baseMediaDecodeTime }),
        trun
      )
    );
    trackData.baseMediaDecodeTime += duration;
    trun.set("data_offset", moof.byteLength + 8);
    updateRateInfo(trackData, { byteLength, duration });
    return moof;
  }
  /**
   * Creates an mdat box containing the elementary stream data.
   * @param  data - Elementary stream data
   * @return mdat Box
   */
  mdat(data) {
    const box = new Box("mdat");
    box.add("data", data);
    return box;
  }
  setPresentationTime(trackId, ntpTimestamp) {
    if (!this.ntpPresentationTime && ntpTimestamp && trackId === this.videoTrackId) {
      const trackOffset = trackId - 1;
      const trackData = this.trackData[trackOffset];
      this.ntpPresentationTime = ntpTimestamp - 1e3 * (trackData.baseMediaDecodeTime / trackData.clockrate);
    }
  }
};

// src/components/mp4muxer/index.ts
var Mp4Muxer = class extends Tube {
  /**
   * Create a new mp4muxer component.
   * @return {undefined}
   */
  constructor() {
    const boxBuilder = new BoxBuilder();
    const onSync = (ntpPresentationTime) => {
      this.onSync && this.onSync(ntpPresentationTime);
    };
    const incoming = new Transform7({
      objectMode: true,
      transform(msg, encoding, callback) {
        if (msg.type === 5 /* SDP */) {
          const now = Math.floor((/* @__PURE__ */ new Date()).getTime() / 1e3 + 2082852e3);
          const ftyp = new Box("ftyp");
          const moov = boxBuilder.moov(msg.sdp, now);
          const data = Buffer.allocUnsafe(ftyp.byteLength + moov.byteLength);
          ftyp.copy(data, 0);
          moov.copy(data, ftyp.byteLength);
          debug4("msl:mp4:isom")(`ftyp: ${ftyp.format()}`);
          debug4("msl:mp4:isom")(`moov: ${moov.format()}`);
          const tracks = msg.sdp.media.map((media) => {
            return {
              type: media.type,
              encoding: media.rtpmap && media.rtpmap.encodingName,
              mime: media.mime,
              codec: media.codec
            };
          });
          this.push({ type: 8 /* ISOM */, data, tracks, ftyp, moov });
        } else if (msg.type === 6 /* ELEMENTARY */ || msg.type === 7 /* H264 */) {
          const { payloadType: payloadType2, timestamp: timestamp2, ntpTimestamp } = msg;
          const trackId = boxBuilder.trackIdMap[payloadType2];
          if (trackId) {
            if (!boxBuilder.ntpPresentationTime) {
              boxBuilder.setPresentationTime(trackId, ntpTimestamp);
              if (boxBuilder.ntpPresentationTime) {
                onSync(boxBuilder.ntpPresentationTime);
              }
            }
            let checkpointTime;
            const idrPicture = msg.type === 7 /* H264 */ ? msg.nalType === 5 /* IDR_PICTURE */ : void 0;
            if (boxBuilder.ntpPresentationTime && idrPicture && msg.ntpTimestamp !== void 0) {
              checkpointTime = (msg.ntpTimestamp - boxBuilder.ntpPresentationTime) / 1e3;
            }
            const byteLength = msg.data.byteLength;
            const moof = boxBuilder.moof({ trackId, timestamp: timestamp2, byteLength });
            const mdat = boxBuilder.mdat(msg.data);
            const data = Buffer.allocUnsafe(moof.byteLength + mdat.byteLength);
            moof.copy(data, 0);
            mdat.copy(data, moof.byteLength);
            this.push({
              type: 8 /* ISOM */,
              data,
              moof,
              mdat,
              ntpTimestamp,
              checkpointTime
            });
          }
        } else {
          this.push(msg);
        }
        callback();
      }
    });
    super(incoming);
    __publicField(this, "boxBuilder");
    __publicField(this, "onSync");
    this.boxBuilder = boxBuilder;
  }
  get bitrate() {
    return this.boxBuilder.trackData && this.boxBuilder.trackData.map((data) => data.bitrate);
  }
  get framerate() {
    return this.boxBuilder.trackData && this.boxBuilder.trackData.map((data) => data.framerate);
  }
  get ntpPresentationTime() {
    return this.boxBuilder.ntpPresentationTime;
  }
};

// src/components/mse/index.ts
import registerDebug2 from "debug";
import { Readable as Readable5, Writable as Writable4 } from "stream";

// src/utils/protocols/rtcp.ts
var RTCPPacketType = /* @__PURE__ */ ((RTCPPacketType2) => {
  RTCPPacketType2[RTCPPacketType2["SR"] = 200] = "SR";
  RTCPPacketType2[RTCPPacketType2["RR"] = 201] = "RR";
  RTCPPacketType2[RTCPPacketType2["SDES"] = 202] = "SDES";
  RTCPPacketType2[RTCPPacketType2["BYE"] = 203] = "BYE";
  RTCPPacketType2[RTCPPacketType2["APP"] = 204] = "APP";
  return RTCPPacketType2;
})(RTCPPacketType || {});
var parseBase = (buffer) => ({
  version: buffer[0] >>> 6,
  padding: !!(buffer[0] & POS[2]),
  count: buffer[0] & 31,
  packetType: buffer.readUInt8(1),
  length: buffer.readUInt16BE(2)
});
var parseRtcp = (buffer) => {
  const base = parseBase(buffer);
  switch (base.packetType) {
    case 200 /* SR */:
      return parseSR(buffer, base);
    case 201 /* RR */:
      return parseRR(buffer, base);
    case 202 /* SDES */:
      return parseSDES(buffer, base);
    case 203 /* BYE */:
      return parseBYE(buffer, base);
    case 204 /* APP */:
      return parseAPP(buffer, base);
    default:
      return base;
  }
};
var rtcpMessageFromBuffer = (channel, buffer) => {
  return {
    type: 3 /* RTCP */,
    data: buffer,
    channel,
    rtcp: parseRtcp(buffer)
  };
};
var SR = {
  packetType: 200
};
var parseReportBlocks = (count, buffer, offset) => {
  const reports = [];
  for (let reportNumber = 0; reportNumber < count; reportNumber++) {
    const o = offset + reportNumber * 24;
    reports.push({
      syncSource: buffer.readUInt32BE(o + 0),
      fractionLost: buffer.readUInt8(o + 4),
      cumulativeNumberOfPacketsLost: buffer.readUIntBE(o + 5, 3),
      extendedHighestSequenceNumberReceived: buffer.readUInt32BE(o + 8),
      interarrivalJitter: buffer.readUInt32BE(o + 12),
      lastSRTimestamp: buffer.readUInt32BE(o + 16),
      delaySinceLastSR: buffer.readUInt32BE(o + 20)
    });
  }
  return reports;
};
var parseSR = (buffer, base) => __spreadProps(__spreadValues({}, base), {
  syncSource: buffer.readUInt32BE(4),
  ntpMost: buffer.readUInt32BE(8),
  ntpLeast: buffer.readUInt32BE(12),
  rtpTimestamp: buffer.readUInt32BE(16),
  sendersPacketCount: buffer.readUInt32BE(20),
  sendersOctetCount: buffer.readUInt32BE(24),
  reports: parseReportBlocks(base.count, buffer, 28)
});
var isRtcpSR = (rtcp) => rtcp.packetType === 200 /* SR */;
var parseRR = (buffer, base) => __spreadProps(__spreadValues({}, base), {
  syncSource: buffer.readUInt32BE(4),
  reports: parseReportBlocks(base.count, buffer, 8)
});
var isRtcpRR = (rtcp) => rtcp.packetType === 201 /* RR */;
var SDESItem = /* @__PURE__ */ ((SDESItem2) => {
  SDESItem2[SDESItem2["CNAME"] = 1] = "CNAME";
  SDESItem2[SDESItem2["NAME"] = 2] = "NAME";
  SDESItem2[SDESItem2["EMAIL"] = 3] = "EMAIL";
  SDESItem2[SDESItem2["PHONE"] = 4] = "PHONE";
  SDESItem2[SDESItem2["LOC"] = 5] = "LOC";
  SDESItem2[SDESItem2["TOOL"] = 6] = "TOOL";
  SDESItem2[SDESItem2["NOTE"] = 7] = "NOTE";
  SDESItem2[SDESItem2["PRIV"] = 8] = "PRIV";
  return SDESItem2;
})(SDESItem || {});
var parseSDES = (buffer, base) => {
  const sourceDescriptions = [];
  let offset = 4;
  for (let block = 0; block < base.count; block++) {
    const chunk = {
      source: buffer.readUInt32BE(offset),
      items: []
    };
    offset += 4;
    while (true) {
      const itemType = buffer.readUInt8(offset++);
      if (itemType === 0) {
        if (offset % 4 !== 0) {
          offset += 4 - offset % 4;
        }
        break;
      }
      const length = buffer.readUInt8(offset++);
      if (itemType === 8 /* PRIV */) {
        const prefixLength = buffer.readUInt8(offset);
        const prefix = buffer.toString(
          "utf8",
          offset + 1,
          offset + 1 + prefixLength
        );
        const value = buffer.toString(
          "utf8",
          offset + 1 + prefixLength,
          offset + length
        );
        chunk.items.push([8 /* PRIV */, prefix, value]);
      } else {
        const value = buffer.toString("utf8", offset, offset + length);
        chunk.items.push([itemType, value]);
      }
      offset += length;
    }
    sourceDescriptions.push(chunk);
  }
  return __spreadProps(__spreadValues({}, base), {
    syncSource: buffer.readUInt32BE(4),
    sourceDescriptions
  });
};
var isRtcpSDES = (rtcp) => rtcp.packetType === 202 /* SDES */;
var parseBYE = (buffer, base) => {
  const sources = [];
  for (let block = 0; block < base.count; block++) {
    sources.push(buffer.readUInt32BE(4 + 4 * block));
  }
  let reason;
  if (base.length > base.count) {
    const start = 4 + 4 * base.count;
    const length = buffer.readUInt8(start);
    reason = buffer.toString("utf-8", start + 1, start + 1 + length);
  }
  return __spreadProps(__spreadValues({}, base), {
    sources,
    reason
  });
};
var isRtcpBye = (rtcp) => rtcp.packetType === 203 /* BYE */;
var parseAPP = (buffer, base) => {
  return __spreadProps(__spreadValues({}, base), {
    subtype: base.count,
    source: buffer.readUInt32BE(4),
    name: buffer.toString("ascii", 8, 12),
    data: buffer.slice(12)
  });
};
var isRtcpApp = (rtcp) => rtcp.packetType === 204 /* APP */;

// src/components/mse/index.ts
var TRIGGER_THRESHOLD = 100;
var debug5 = registerDebug2("msl:mse");
var MseSink = class extends Sink {
  /**
   * Create a Media component.
   *
   * The constructor sets up two streams and connects them to the MediaSource.
   *
   * @param el - A video element to connect the media source to
   */
  constructor(el) {
    if (el === void 0) {
      throw new Error("video element argument missing");
    }
    let mse;
    let sourceBuffer;
    const incoming = new Writable4({
      objectMode: true,
      write: (msg, _, callback) => {
        var _a, _b;
        if (msg.type === 8 /* ISOM */) {
          this._done = callback;
          if (msg.tracks !== void 0 || msg.mime !== void 0) {
            const tracks = (_a = msg.tracks) != null ? _a : [];
            const mimeCodecs = tracks.map((track) => track.mime).filter((mime) => mime);
            const codecs = mimeCodecs.length !== 0 ? mimeCodecs.join(", ") : "avc1.640029, mp4a.40.2";
            const mimeType = (_b = msg.mime) != null ? _b : `video/mp4; codecs="${codecs}"`;
            if (!MediaSource.isTypeSupported(mimeType)) {
              incoming.emit("error", `unsupported media type: ${mimeType}`);
              return;
            }
            this._lastCheckpointTime = 0;
            mse = new MediaSource();
            el.src = window.URL.createObjectURL(mse);
            const handler = () => {
              if (mse === void 0) {
                incoming.emit("error", "no MediaSource instance");
                return;
              }
              window.URL.revokeObjectURL(el.src);
              mse.removeEventListener("sourceopen", handler);
              this.onSourceOpen && this.onSourceOpen(mse, tracks);
              sourceBuffer = this.addSourceBuffer(el, mse, mimeType);
              sourceBuffer.onerror = (e) => {
                console.error("error on SourceBuffer: ", e);
                incoming.emit("error");
              };
              try {
                sourceBuffer.appendBuffer(msg.data);
              } catch (err) {
                debug5("failed to append to SourceBuffer: ", err, msg);
              }
            };
            mse.addEventListener("sourceopen", handler);
          } else {
            this._lastCheckpointTime = msg.checkpointTime !== void 0 ? msg.checkpointTime : this._lastCheckpointTime;
            try {
              sourceBuffer == null ? void 0 : sourceBuffer.appendBuffer(msg.data);
            } catch (e) {
              debug5("failed to append to SourceBuffer: ", e, msg);
            }
          }
        } else if (msg.type === 3 /* RTCP */) {
          if (isRtcpBye(msg.rtcp)) {
            (mse == null ? void 0 : mse.readyState) === "open" && mse.endOfStream();
          }
          callback();
        } else {
          callback();
        }
      }
    });
    incoming.on("finish", () => {
      console.warn("incoming stream finished: end stream");
      mse && mse.readyState === "open" && mse.endOfStream();
    });
    incoming.on("error", (msg) => {
      console.error("error on incoming stream: ", msg);
      if (sourceBuffer && sourceBuffer.updating) {
        sourceBuffer.addEventListener("updateend", () => {
          (mse == null ? void 0 : mse.readyState) === "open" && mse.endOfStream();
        });
      } else {
        (mse == null ? void 0 : mse.readyState) === "open" && mse.endOfStream();
      }
    });
    const outgoing = new Readable5({
      objectMode: true,
      read() {
      }
    });
    outgoing.on("error", () => {
      console.warn("outgoing stream broke somewhere");
    });
    super(incoming, outgoing);
    __publicField(this, "_videoEl");
    __publicField(this, "_done");
    __publicField(this, "_lastCheckpointTime");
    __publicField(this, "onSourceOpen");
    this._videoEl = el;
    this._lastCheckpointTime = 0;
  }
  /**
   * Add a new sourceBuffer to the mediaSource and remove old ones.
   * @param el - The media element holding the media source.
   * @param mse - The media source the buffer should be attached to.
   * @param mimeType - MIME type and codecs, e.g.: 'video/mp4; codecs="avc1.4D0029, mp4a.40.2"'
   */
  addSourceBuffer(el, mse, mimeType) {
    const sourceBuffer = mse.addSourceBuffer(mimeType);
    let trigger = 0;
    const onUpdateEndHandler = () => {
      ;
      ++trigger;
      if (trigger > TRIGGER_THRESHOLD && sourceBuffer.buffered.length) {
        trigger = 0;
        const index = sourceBuffer.buffered.length - 1;
        const start = sourceBuffer.buffered.start(index);
        const end = Math.min(el.currentTime, this._lastCheckpointTime) - 10;
        try {
          if (end > start) {
            sourceBuffer.remove(start, end);
            return;
          }
        } catch (e) {
          console.warn(e);
        }
      }
      this._done && this._done();
    };
    sourceBuffer.addEventListener("updateend", onUpdateEndHandler);
    return sourceBuffer;
  }
  get currentTime() {
    return this._videoEl.currentTime;
  }
  play() {
    return __async(this, null, function* () {
      return yield this._videoEl.play();
    });
  }
  pause() {
    return this._videoEl.pause();
  }
};

// src/components/onvifdepay/index.ts
import { Transform as Transform8 } from "stream";
var ONVIFDepay = class extends Tube {
  constructor() {
    let XMLPayloadType;
    let packets = [];
    const incoming = new Transform8({
      objectMode: true,
      transform(msg, encoding, callback) {
        if (msg.type === 5 /* SDP */) {
          let validMedia;
          for (const media of msg.sdp.media) {
            if (media.type === "application" && media.rtpmap && media.rtpmap.encodingName === "VND.ONVIF.METADATA") {
              validMedia = media;
            }
          }
          if (validMedia && validMedia.rtpmap) {
            XMLPayloadType = Number(validMedia.rtpmap.payloadType);
          }
          callback(void 0, msg);
        } else if (msg.type === 2 /* RTP */ && payloadType(msg.data) === XMLPayloadType) {
          packets.push(payload(msg.data));
          if (marker(msg.data) && packets.length > 0) {
            const xmlMsg = {
              timestamp: timestamp(msg.data),
              ntpTimestamp: msg.ntpTimestamp,
              payloadType: payloadType(msg.data),
              data: Buffer.concat(packets),
              type: 9 /* XML */
            };
            callback(void 0, xmlMsg);
            packets = [];
            return;
          }
          callback();
        } else {
          callback(void 0, msg);
        }
      }
    });
    super(incoming);
  }
};

// src/components/rtsp-parser/index.ts
import { Transform as Transform9 } from "stream";

// src/components/rtsp-parser/builder.ts
import debug6 from "debug";
var DEFAULT_PROTOCOL = "RTSP/1.0";
var builder = (msg) => {
  if (!msg.method || !msg.uri) {
    throw new Error("message needs to contain a method and a uri");
  }
  const protocol = msg.protocol || DEFAULT_PROTOCOL;
  const headers = msg.headers || {};
  const messageString = [
    `${msg.method} ${msg.uri} ${protocol}`,
    Object.entries(headers).map(([key, value]) => `${key}: ${value}`).join("\r\n"),
    "\r\n"
  ].join("\r\n");
  debug6("msl:rtsp:outgoing")(messageString);
  return Buffer.from(messageString);
};

// src/utils/protocols/rtsp.ts
var extractHeaderValue = (buffer, header) => {
  const anchor = `
${header.toLowerCase()}: `;
  const start = buffer.toString().toLowerCase().indexOf(anchor);
  if (start >= 0) {
    const end = buffer.indexOf("\n", start + anchor.length);
    const headerValue = buffer.toString("ascii", start + anchor.length, end).trim();
    return headerValue;
  }
  return null;
};
var sequence = (buffer) => {
  const val = extractHeaderValue(buffer, "CSeq");
  if (val !== null) {
    return Number(val);
  }
  return null;
};
var sessionId = (buffer) => {
  const val = extractHeaderValue(buffer, "Session");
  return val ? val.split(";")[0] : null;
};
var sessionTimeout = (buffer) => {
  const val = extractHeaderValue(buffer, "Session");
  if (val === null) {
    return null;
  }
  const defaultTimeout = 60;
  const timeoutToken = "timeout=";
  const timeoutPosition = val.toLowerCase().indexOf(timeoutToken);
  if (timeoutPosition !== -1) {
    let timeoutVal = val.substring(timeoutPosition + timeoutToken.length);
    timeoutVal = timeoutVal.split(";")[0];
    const parsedTimeout = parseInt(timeoutVal);
    return isNaN(parsedTimeout) ? defaultTimeout : parsedTimeout;
  }
  return defaultTimeout;
};
var statusCode = (buffer) => {
  return Number(buffer.toString("ascii", 9, 12));
};
var contentBase = (buffer) => {
  return extractHeaderValue(buffer, "Content-Base");
};
var contentLocation = (buffer) => {
  return extractHeaderValue(buffer, "Content-Location");
};
var connectionEnded = (buffer) => {
  const connectionToken = extractHeaderValue(buffer, "Connection");
  return connectionToken !== null && connectionToken.toLowerCase() === "close";
};
var range = (buffer) => {
  const npt = extractHeaderValue(buffer, "Range");
  if (npt !== null) {
    return npt.split("=")[1].split("-");
  }
  return void 0;
};
var bodyOffset = (chunk) => {
  const bodyOffsets = ["\n\n", "\r\r", "\r\n\r\n"].map((s) => {
    const offset = chunk.indexOf(s);
    if (offset !== -1) {
      return offset + s.length;
    }
    return offset;
  }).filter((offset) => offset !== -1);
  if (bodyOffsets.length > 0) {
    return bodyOffsets.reduce((acc, offset) => {
      return Math.min(acc, offset);
    });
  }
  return -1;
};

// src/utils/protocols/sdp.ts
var extractLineVals = (buffer, lineStart, start = 0) => {
  const anchor = `
${lineStart}`;
  start = buffer.indexOf(anchor, start);
  let end = 0;
  const ret = [];
  while (start >= 0) {
    end = buffer.indexOf("\n", start + anchor.length);
    ret.push(buffer.toString("ascii", start + anchor.length, end).trim());
    start = buffer.indexOf(anchor, end);
  }
  return ret;
};
var newMediaLevel = (line) => {
  return line.match(/^m=/);
};
var splitOnFirst = (c, text) => {
  const p = text.indexOf(c);
  if (p < 0) {
    return [text.slice(0)];
  }
  return [text.slice(0, p), text.slice(p + 1)];
};
var attributeParsers = {
  fmtp: (value) => {
    const [format, stringParameters] = splitOnFirst(" ", value);
    switch (format) {
      default: {
        const pairs = stringParameters.trim().split(";");
        const parameters = {};
        pairs.forEach((pair) => {
          const [key, val] = splitOnFirst("=", pair);
          const normalizedKey = key.trim().toLowerCase();
          if (normalizedKey !== "") {
            parameters[normalizedKey] = val.trim();
          }
        });
        return { format, parameters };
      }
    }
  },
  framerate: Number,
  rtpmap: (value) => {
    const [payloadType2, encoding] = splitOnFirst(" ", value);
    const [encodingName, clockrate, encodingParameters] = encoding.toUpperCase().split("/");
    if (encodingParameters === void 0) {
      return {
        payloadType: Number(payloadType2),
        encodingName,
        clockrate: Number(clockrate)
      };
    }
    return {
      payloadType: Number(payloadType2),
      encodingName,
      clockrate: Number(clockrate),
      encodingParameters
    };
  },
  transform: (value) => {
    return value.split(";").map((row) => row.split(",").map(Number));
  },
  "x-sensor-transform": (value) => {
    return value.split(";").map((row) => row.split(",").map(Number));
  },
  framesize: (value) => {
    return value.split(" ")[1].split("-").map(Number);
  }
};
var parseAttribute = (body) => {
  const [attribute, value] = splitOnFirst(":", body);
  if (value === void 0) {
    return { [attribute]: true };
  }
  if (attributeParsers[attribute] !== void 0) {
    return { [attribute]: attributeParsers[attribute](value) };
  }
  return { [attribute]: value };
};
var extractField = (line) => {
  const prefix = line.slice(0, 1);
  const body = line.slice(2);
  switch (prefix) {
    case "v":
      return { version: body };
    case "o": {
      const [
        username,
        sessionId2,
        sessionVersion,
        netType,
        addrType,
        unicastAddress
      ] = body.split(" ");
      return {
        origin: {
          addrType,
          netType,
          sessionId: sessionId2,
          sessionVersion,
          unicastAddress,
          username
        }
      };
    }
    case "s":
      return { sessionName: body };
    case "i":
      return { sessionInformation: body };
    case "u":
      return { uri: body };
    case "e":
      return { email: body };
    case "p":
      return { phone: body };
    case "c": {
      const [connectionNetType, connectionAddrType, connectionAddress] = body.split(" ");
      return {
        connectionData: {
          addrType: connectionAddrType,
          connectionAddress,
          netType: connectionNetType
        }
      };
    }
    case "b": {
      const [bwtype, bandwidth] = body.split(":");
      return { bwtype, bandwidth };
    }
    case "t": {
      const [startTime, stopTime] = body.split(" ").map(Number);
      return { time: { startTime, stopTime } };
    }
    case "r": {
      const [repeatInterval, activeDuration, ...offsets] = body.split(" ").map(Number);
      return {
        repeatTimes: { repeatInterval, activeDuration, offsets }
      };
    }
    case "z":
      return;
    case "k":
      return;
    case "a":
      return parseAttribute(body);
    case "m": {
      const [type, port, protocol, fmt] = body.split(" ");
      return { type, port: Number(port), protocol, fmt: Number(fmt) };
    }
    default:
  }
};
var extractURIs = (buffer) => {
  const seekFrom = buffer.indexOf("\nm=");
  return extractLineVals(buffer, "a=control:", seekFrom);
};
var parse2 = (buffer) => {
  const sdp = buffer.toString("ascii").split("\n").map((s) => s.trim());
  const struct = { session: {}, media: [] };
  let mediaCounter = 0;
  let current = struct.session;
  for (const line of sdp) {
    if (newMediaLevel(line)) {
      struct.media[mediaCounter] = {};
      current = struct.media[mediaCounter];
      ++mediaCounter;
    }
    current = Object.assign(current, extractField(line));
  }
  return struct;
};
var messageFromBuffer = (buffer) => {
  return {
    type: 5 /* SDP */,
    data: buffer,
    sdp: parse2(buffer)
  };
};

// src/components/rtsp-parser/parser.ts
var INTERLEAVED_HEADER_BYTES = 4;
var ASCII_DOLLAR = 36;
var rtpPacketInfo = (chunks) => {
  const header = Buffer.alloc(INTERLEAVED_HEADER_BYTES);
  let i = 0;
  let bytesRead = 0;
  while (bytesRead < header.length) {
    const chunk = chunks[i++];
    const bytesToRead = Math.min(chunk.length, header.length - bytesRead);
    chunk.copy(header, bytesRead, 0, bytesToRead);
    bytesRead += bytesToRead;
  }
  const channel = header[1];
  const begin = header.length;
  const length = header.readUInt16BE(2);
  const end = begin + length;
  return { channel, begin, end };
};
var Parser = class {
  /**
   * Create a new Parser object.
   * @return {undefined}
   */
  constructor() {
    __publicField(this, "_chunks", []);
    __publicField(this, "_length", 0);
    __publicField(this, "_state", 0 /* IDLE */);
    __publicField(this, "_packet");
    this._init();
  }
  /**
   * Initialize the internal properties to their default starting
   * values.
   * @return {undefined}
   */
  _init() {
    this._chunks = [];
    this._length = 0;
    this._state = 0 /* IDLE */;
  }
  _push(chunk) {
    this._chunks.push(chunk);
    this._length += chunk.length;
  }
  /**
   * Extract RTSP messages.
   * @return {Array} An array of messages, possibly empty.
   */
  _parseRtsp() {
    const messages = [];
    const buffer = Buffer.concat(this._chunks);
    const chunkBodyOffset = bodyOffset(buffer);
    if (chunkBodyOffset === -1) {
      return messages;
    }
    const rtspHeaderLength = chunkBodyOffset;
    const contentLength = extractHeaderValue(buffer, "Content-Length");
    if (contentLength && parseInt(contentLength) > buffer.length - rtspHeaderLength) {
      return messages;
    }
    this._init();
    if (rtspHeaderLength === buffer.length || buffer[rtspHeaderLength] === ASCII_DOLLAR) {
      const packet = buffer.slice(0, rtspHeaderLength);
      messages.push({ type: 4 /* RTSP */, data: packet });
      const trailing = buffer.slice(rtspHeaderLength);
      this._push(trailing);
    } else {
      const packet = buffer;
      const body = buffer.slice(rtspHeaderLength);
      messages.push({ type: 4 /* RTSP */, data: packet });
      messages.push(messageFromBuffer(body));
    }
    return messages;
  }
  /**
   * Extract RTP/RTCP messages.
   * @return {Array} An array of messages, possibly empty.
   */
  _parseInterleaved() {
    const messages = [];
    if (this._length < INTERLEAVED_HEADER_BYTES) {
      return messages;
    }
    if (!this._packet) {
      this._packet = rtpPacketInfo(this._chunks);
    }
    if (this._length < this._packet.end) {
      return messages;
    }
    const buffer = Buffer.concat(this._chunks);
    const packet = buffer.slice(this._packet.begin, this._packet.end);
    const trailing = buffer.slice(this._packet.end);
    const channel = this._packet.channel;
    delete this._packet;
    this._init();
    this._push(trailing);
    if (channel % 2 === 0) {
      messages.push({ type: 2 /* RTP */, data: packet, channel });
    } else {
      let rtcpPackets = packet;
      do {
        const rtcpByteSize = rtcpPackets.readUInt16BE(2) * 4 + 4;
        messages.push(
          rtcpMessageFromBuffer(channel, rtcpPackets.slice(0, rtcpByteSize))
        );
        rtcpPackets = rtcpPackets.slice(rtcpByteSize);
      } while (rtcpPackets.length > 0);
    }
    return messages;
  }
  /**
   * Set the internal state based on the type of the first chunk
   */
  _setState() {
    while (this._chunks.length > 0 && this._chunks[0].length === 0) {
      this._chunks.shift();
    }
    const firstChunk = this._chunks[0];
    if (this._chunks.length === 0) {
      this._state = 0 /* IDLE */;
    } else if (firstChunk[0] === ASCII_DOLLAR) {
      this._state = 1 /* INTERLEAVED */;
    } else if (firstChunk.toString("ascii", 0, 4) === "RTSP") {
      this._state = 2 /* RTSP */;
    } else {
      throw new Error(`Unknown chunk of length ${firstChunk.length}`);
    }
  }
  /**
   * Add the next chunk of data to the parser and extract messages.
   * If no message can be extracted, an empty array is returned, otherwise
   * an array of messages is returned.
   * @param  chunk - The next piece of data.
   * @return An array of messages, possibly empty.
   */
  parse(chunk) {
    this._push(chunk);
    if (this._state === 0 /* IDLE */) {
      this._setState();
    }
    let messages = [];
    let done = false;
    while (!done) {
      let extracted = [];
      switch (this._state) {
        case 0 /* IDLE */:
          break;
        case 1 /* INTERLEAVED */:
          extracted = this._parseInterleaved();
          break;
        case 2 /* RTSP */:
          extracted = this._parseRtsp();
          break;
        default:
          throw new Error("internal error: unknown state");
      }
      if (extracted.length > 0) {
        messages = messages.concat(extracted);
      } else {
        done = true;
      }
      this._setState();
    }
    return messages;
  }
};

// src/components/rtsp-parser/index.ts
var RtspParser = class extends Tube {
  constructor() {
    const parser = new Parser();
    const incoming = new Transform9({
      objectMode: true,
      transform(msg, encoding, callback) {
        if (msg.type === 1 /* RAW */) {
          try {
            parser.parse(msg.data).forEach((message) => incoming.push(message));
            callback();
          } catch (e) {
            const err = e;
            callback(err);
          }
        } else {
          callback(void 0, msg);
        }
      }
    });
    const outgoing = new Transform9({
      objectMode: true,
      transform(msg, encoding, callback) {
        if (msg.type === 4 /* RTSP */) {
          const data = builder(msg);
          callback(void 0, { type: 1 /* RAW */, data });
        } else {
          callback(void 0, msg);
        }
      }
    });
    super(incoming, outgoing);
  }
};

// src/components/rtsp-session/index.ts
import debug7 from "debug";
import { Transform as Transform10 } from "stream";

// src/utils/config.ts
var merge = (template, override) => {
  let cleanOverride;
  if (override !== void 0) {
    if (typeof override !== "object") {
      throw new Error("merge expects override to be an object!");
    } else {
      cleanOverride = Object.keys(override).reduce(
        (acc, key) => {
          if (override[key] !== void 0) {
            acc[key] = override[key];
          }
          return acc;
        },
        {}
      );
    }
  }
  return Object.assign({}, template, cleanOverride);
};

// src/utils/protocols/ntp.ts
var NTP_UNIX_EPOCH_OFFSET = Date.UTC(1900, 0, 1);
function getTime(ntpMost, ntpLeast) {
  const ntpMilliSeconds = (ntpMost + ntpLeast / 4294967296) * 1e3;
  return NTP_UNIX_EPOCH_OFFSET + ntpMilliSeconds;
}

// src/components/rtsp-session/index.ts
function isAbsolute(url) {
  return /^[^:]+:\/\//.test(url);
}
var RTSP_METHOD = /* @__PURE__ */ ((RTSP_METHOD2) => {
  RTSP_METHOD2["OPTIONS"] = "OPTIONS";
  RTSP_METHOD2["DESCRIBE"] = "DESCRIBE";
  RTSP_METHOD2["SETUP"] = "SETUP";
  RTSP_METHOD2["PLAY"] = "PLAY";
  RTSP_METHOD2["PAUSE"] = "PAUSE";
  RTSP_METHOD2["TEARDOWN"] = "TEARDOWN";
  return RTSP_METHOD2;
})(RTSP_METHOD || {});
var MIN_SESSION_TIMEOUT = 5;
var defaultConfig = (hostname = typeof window === "undefined" ? "" : window.location.hostname, parameters = []) => {
  const uri = parameters.length > 0 ? `rtsp://${hostname}/axis-media/media.amp?${parameters.join("&")}` : `rtsp://${hostname}/axis-media/media.amp`;
  return { uri };
};
var RTSPResponseError = class extends Error {
  constructor(message, code) {
    super(message);
    __publicField(this, "code");
    this.name = "RTSPResponseError";
    this.code = code;
  }
};
var RtspSession = class extends Tube {
  /**
   * Create a new RTSP session controller component.
   * @param  [config] Details about the session.
   * @param  [config.hostname] The RTSP server hostname
   * @param  [config.parameters] The RTSP URI parameters
   * @param  [config.uri] The full RTSP URI (overrides any hostname/parameters)
   * @param  [config.defaultHeaders] Default headers to use (for all methods).
   * @param  [config.headers] Headers to use (mapped to each method).
   */
  constructor(config = {}) {
    const { uri, headers, defaultHeaders } = merge(
      defaultConfig(config.hostname, config.parameters),
      config
    );
    const incoming = new Transform10({
      objectMode: true,
      transform: (msg, _, callback) => {
        if (msg.type === 4 /* RTSP */) {
          this._onRtsp(msg);
          callback();
        } else if (msg.type === 3 /* RTCP */) {
          this._onRtcp(msg);
          this.onRtcp && this.onRtcp(msg.rtcp);
          callback(void 0, msg);
        } else if (msg.type === 2 /* RTP */) {
          this._onRtp(msg);
          callback(void 0, msg);
        } else if (msg.type === 5 /* SDP */) {
          this._onSdp(msg);
          this.onSdp && this.onSdp(msg.sdp);
          callback(void 0, msg);
        } else {
          callback(void 0, msg);
        }
      }
    });
    incoming.on("end", () => {
      this._outgoingClosed = true;
    });
    super(incoming);
    __publicField(this, "uri");
    __publicField(this, "headers");
    __publicField(this, "defaultHeaders");
    __publicField(this, "t0");
    __publicField(this, "n0");
    __publicField(this, "clockrates");
    __publicField(this, "startTime");
    __publicField(this, "onRtcp");
    __publicField(this, "onSdp");
    __publicField(this, "onError");
    __publicField(this, "onPlay");
    __publicField(this, "retry");
    __publicField(this, "_outgoingClosed");
    __publicField(this, "_sequence");
    __publicField(this, "_callStack");
    __publicField(this, "_callHistory");
    __publicField(this, "_state");
    __publicField(this, "_waiting");
    __publicField(this, "_contentBase");
    __publicField(this, "_contentLocation");
    __publicField(this, "_sessionId");
    __publicField(this, "_sessionControlURL");
    __publicField(this, "_renewSessionInterval");
    this._outgoingClosed = false;
    this._reset();
    this.update(uri, headers, defaultHeaders);
    this._sessionControlURL = this._controlURL();
  }
  /**
   * Update the cached RTSP uri and headers.
   * @param  uri - The RTSP URI.
   * @param  headers - Maps commands to headers.
   * @param  defaultHeaders - Default headers.
   */
  update(uri, headers = {}, defaultHeaders = {}) {
    if (uri === void 0) {
      throw new Error(
        "You must supply an uri when creating a RtspSessionComponent"
      );
    }
    this.uri = uri;
    this.defaultHeaders = defaultHeaders;
    this.headers = Object.assign(
      {
        ["OPTIONS" /* OPTIONS */]: {},
        ["PLAY" /* PLAY */]: {},
        ["SETUP" /* SETUP */]: { Blocksize: "64000" },
        ["DESCRIBE" /* DESCRIBE */]: { Accept: "application/sdp" },
        ["PAUSE" /* PAUSE */]: {}
      },
      headers
    );
  }
  /**
   * Restore the initial values to the state they were in before any RTSP
   * connection was made.
   */
  _reset() {
    this._sequence = 1;
    this.retry = () => console.error("No request sent, can't retry");
    this._callStack = [];
    this._callHistory = [];
    this._state = "idle" /* IDLE */;
    this._waiting = false;
    this._contentBase = null;
    this._sessionId = null;
    if (this._renewSessionInterval !== null) {
      clearInterval(this._renewSessionInterval);
    }
    this._renewSessionInterval = null;
    this.t0 = void 0;
    this.n0 = void 0;
    this.clockrates = void 0;
  }
  _controlURL(attribute) {
    var _a, _b;
    if (attribute !== void 0 && isAbsolute(attribute)) {
      return attribute;
    }
    const baseURL = (_b = (_a = this._contentBase) != null ? _a : this._contentLocation) != null ? _b : this.uri;
    if (baseURL === null || baseURL === void 0) {
      throw new Error(
        "relative or missing control attribute but no base URL available"
      );
    }
    if (attribute === void 0 || attribute === "*") {
      return baseURL;
    }
    return new URL(attribute, baseURL).href;
  }
  /**
   * Handles incoming RTSP messages and send the next command in the queue.
   * @param  msg - An incoming RTSP message.
   */
  _onRtsp(msg) {
    this._waiting = false;
    const status = statusCode(msg.data);
    const ended = connectionEnded(msg.data);
    const seq = sequence(msg.data);
    if (seq === null) {
      throw new Error("rtsp: expected sequence number");
    }
    if (this._callHistory === void 0) {
      throw new Error("rtsp: internal error");
    }
    const method = this._callHistory[seq - 1];
    debug7("msl:rtsp:incoming")(`${msg.data}`);
    if (!this._sessionId && !ended) {
      this._sessionId = sessionId(msg.data);
      const _sessionTimeout = sessionTimeout(msg.data);
      if (_sessionTimeout !== null) {
        if (this._renewSessionInterval !== null) {
          clearInterval(this._renewSessionInterval);
        }
        this._renewSessionInterval = setInterval(
          () => {
            this._enqueue({ method: "OPTIONS" /* OPTIONS */ });
            this._dequeue();
          },
          Math.max(MIN_SESSION_TIMEOUT, _sessionTimeout - 5) * 1e3
        );
      }
    }
    if (!this._contentBase) {
      this._contentBase = contentBase(msg.data);
    }
    if (!this._contentLocation) {
      this._contentLocation = contentLocation(msg.data);
    }
    if (status >= 400) {
      this.onError && this.onError(
        new RTSPResponseError(msg.data.toString("ascii"), status)
      );
    }
    if (method === "PLAY" /* PLAY */) {
      this.onPlay && this.onPlay(range(msg.data));
    }
    if (ended) {
      debug7("msl:rtsp:incoming")(
        `RTSP Session ${this._sessionId} ended with statusCode: ${status}`
      );
      this._sessionId = null;
    }
    this._dequeue();
  }
  _onRtcp(msg) {
    if (this.t0 === void 0 || this.n0 === void 0) {
      throw new Error("rtsp: internal error");
    }
    if (isRtcpSR(msg.rtcp)) {
      const rtpChannel = msg.channel - 1;
      this.t0[rtpChannel] = msg.rtcp.rtpTimestamp;
      this.n0[rtpChannel] = getTime(msg.rtcp.ntpMost, msg.rtcp.ntpLeast);
    }
  }
  _onRtp(msg) {
    if (this.t0 === void 0 || this.n0 === void 0 || this.clockrates === void 0) {
      throw new Error("rtsp: internal error");
    }
    const rtpChannel = msg.channel;
    const t0 = this.t0[rtpChannel];
    const n0 = this.n0[rtpChannel];
    if (typeof t0 !== "undefined" && typeof n0 !== "undefined") {
      const clockrate = this.clockrates[rtpChannel];
      const t = timestamp(msg.data);
      const dt = t - t0 | 0;
      msg.ntpTimestamp = dt / clockrate * 1e3 + n0;
    }
  }
  /**
   * Handles incoming SDP messages, reply with SETUP and optionally PLAY.
   * @param  msg - An incoming SDP message.
   */
  _onSdp(msg) {
    this.n0 = {};
    this.t0 = {};
    this.clockrates = {};
    this._sessionControlURL = this._controlURL(msg.sdp.session.control);
    msg.sdp.media.forEach((media, index) => {
      if (media.rtpmap === void 0) {
        return;
      }
      const { clockrate } = media.rtpmap;
      const rtp = index * 2;
      const rtcp = rtp + 1;
      const uri = media.control === void 0 ? this._sessionControlURL : this._controlURL(media.control);
      this._enqueue({
        method: "SETUP" /* SETUP */,
        headers: {
          Transport: `RTP/AVP/TCP;unicast;interleaved=${rtp}-${rtcp}`
        },
        uri
      });
      if (this.clockrates === void 0) {
        return;
      }
      this.clockrates[rtp] = clockrate;
    });
    if (this._state === "playing" /* PLAYING */) {
      this._enqueue({
        method: "PLAY" /* PLAY */,
        headers: {
          Range: `npt=${this.startTime || 0}-`
        },
        uri: this._sessionControlURL
      });
    }
    this._dequeue();
  }
  /**
   * Set up command queue in order to start playing, i.e. PLAY optionally
   * preceeded by OPTIONS/DESCRIBE commands. If not waiting, immediately
   * start sending.
   * @param  startTime - Time (seconds) at which to start playing
   */
  play(startTime = 0) {
    if (this._state === "idle" /* IDLE */) {
      this.startTime = Number(startTime) || 0;
      this._enqueue({ method: "OPTIONS" /* OPTIONS */ });
      this._enqueue({ method: "DESCRIBE" /* DESCRIBE */ });
    } else if (this._state === "paused" /* PAUSED */) {
      if (this._sessionId === null || this._sessionId === void 0) {
        throw new Error("rtsp: internal error");
      }
      this._enqueue({
        method: "PLAY" /* PLAY */,
        headers: {
          Session: this._sessionId
        },
        uri: this._sessionControlURL
      });
    }
    this._state = "playing" /* PLAYING */;
    this._dequeue();
  }
  /**
   * Queue a pause command, and send if not waiting.
   * @return {undefined}
   */
  pause() {
    this._enqueue({ method: "PAUSE" /* PAUSE */ });
    this._state = "paused" /* PAUSED */;
    this._dequeue();
  }
  /**
   * End the session if there is one, otherwise just cancel
   * any outstanding calls on the stack.
   * @return {undefined}
   */
  stop() {
    if (this._sessionId) {
      this._enqueue({ method: "TEARDOWN" /* TEARDOWN */ });
    } else {
      this._callStack = [];
    }
    this._state = "idle" /* IDLE */;
    if (this._renewSessionInterval !== null) {
      clearInterval(this._renewSessionInterval);
      this._renewSessionInterval = null;
    }
    this._dequeue();
  }
  /**
   * Pushes an RTSP request onto the outgoing stream.
   * @param  cmd - The details about the command to send.
   */
  send(cmd) {
    const { method, headers, uri } = cmd;
    if (method === void 0) {
      throw new Error("missing method when send request");
    }
    this._waiting = true;
    this.retry = this.send.bind(this, cmd);
    if (this._sequence === void 0 || this.headers === void 0 || this._callHistory === void 0) {
      throw new Error("rtsp: internal error");
    }
    const message = Object.assign(
      {
        type: 4 /* RTSP */,
        uri: uri || this._sessionControlURL,
        data: Buffer.alloc(0)
        // data is a mandatory field. Not used by session -> parser messages.
      },
      { method, headers },
      {
        headers: Object.assign(
          { CSeq: this._sequence++ },
          this.defaultHeaders,
          // default headers (for all methods)
          this.headers[method],
          // preset headers for this method
          headers
          // headers that came with the invokation
        )
      }
    );
    this._sessionId && (message.headers.Session = this._sessionId);
    this._callHistory.push(method);
    if (!this._outgoingClosed) {
      this.outgoing.push(message);
    } else {
      debug7("msl:rtsp:outgoing")(`Unable to send ${method}, connection closed`);
    }
  }
  /**
   * Push a command onto the call stack.
   * @param  cmd - The command to queue
   */
  _enqueue(cmd) {
    if (this._callStack === void 0) {
      throw new Error("rtsp: internal error");
    }
    this._callStack.push(cmd);
  }
  /**
   * If possible, send the next command on the call stack.
   */
  _dequeue() {
    if (this._callStack === void 0) {
      throw new Error("rtsp: internal error");
    }
    if (!this._waiting && this._callStack.length > 0) {
      const cmd = this._callStack.shift();
      if (cmd !== void 0) {
        this.send(cmd);
      }
    }
  }
};

// src/components/ws-source/index.ts
import debug8 from "debug";
import { Readable as Readable6, Writable as Writable5 } from "stream";

// src/components/ws-source/openwebsocket.ts
var WEBSOCKET_TIMEOUT = 10007;
var defaultConfig2 = (host = window.location.host, scheme = window.location.protocol) => {
  const wsScheme = scheme === "https:" ? "wss:" : "ws:";
  return {
    uri: `${wsScheme}//${host}/rtsp-over-websocket`,
    tokenUri: `${scheme}//${host}/axis-cgi/rtspwssession.cgi`,
    protocol: "binary",
    timeout: WEBSOCKET_TIMEOUT
  };
};
var openWebSocket = (..._0) => __async(void 0, [..._0], function* (config = {}) {
  const { uri, tokenUri, protocol, timeout } = merge(
    defaultConfig2(config.host, config.scheme),
    config
  );
  if (uri === void 0) {
    throw new Error("ws: internal error");
  }
  return yield new Promise((resolve, reject) => {
    try {
      const ws = new WebSocket(uri, protocol);
      const countdown = setTimeout(() => {
        clearTimeout(countdown);
        if (ws.readyState === WebSocket.CONNECTING) {
          ws.onerror = null;
          reject(new Error("websocket connection timed out"));
        }
      }, timeout);
      ws.binaryType = "arraybuffer";
      ws.onerror = (originalError) => {
        clearTimeout(countdown);
        function onLoadToken() {
          if (this.status >= 400) {
            console.warn("failed to load token", this.status, this.responseText);
            reject(originalError);
            return;
          }
          const token = this.responseText.trim();
          const newUri = `${uri}?rtspwssession=${token}`;
          const ws2 = new WebSocket(newUri, protocol);
          ws2.binaryType = "arraybuffer";
          ws2.onerror = (err) => {
            reject(err);
          };
          ws2.onopen = () => resolve(ws2);
        }
        const request = new XMLHttpRequest();
        request.addEventListener("load", onLoadToken);
        request.addEventListener("error", (err) => {
          console.warn("failed to get token");
          reject(err);
        });
        request.addEventListener("abort", () => reject(originalError));
        request.open("GET", `${tokenUri}?${Date.now()}`);
        try {
          request.send();
        } catch (error) {
          reject(originalError);
        }
      };
      ws.onopen = () => {
        clearTimeout(countdown);
        resolve(ws);
      };
    } catch (e) {
      reject(e);
    }
  });
});

// src/components/ws-source/index.ts
var CLOSE_GOING_AWAY = 1001;
var WSSource = class _WSSource extends Source {
  /**
   * Create a WebSocket component.
   *
   * The constructor sets up two streams and connects them to the socket as
   * soon as the socket is available (and open).
   *
   * @param socket - an open WebSocket.
   */
  constructor(socket) {
    if (socket === void 0) {
      throw new Error("socket argument missing");
    }
    const incoming = new Readable6({
      objectMode: true,
      read() {
      }
    });
    socket.onmessage = (msg) => {
      const buffer = Buffer.from(msg.data);
      if (!incoming.push({ data: buffer, type: 1 /* RAW */ })) {
        if (socket.readyState === WebSocket.OPEN) {
          debug8("msl:websocket:incoming")("downstream frozen");
          socket.close();
        }
      }
    };
    incoming.on("error", (e) => {
      console.warn("closing socket due to incoming error", e);
      socket.close();
    });
    const outgoing = new Writable5({
      objectMode: true,
      write(msg, encoding, callback) {
        try {
          socket.send(msg.data);
        } catch (e) {
          console.warn("message lost during send:", msg);
        }
        callback();
      }
    });
    outgoing.on("error", (e) => {
      console.warn("error during websocket send, ignoring:", e);
    });
    outgoing.on("finish", () => {
      debug8("msl:websocket:outgoing")("finish");
      if (socket.readyState !== WebSocket.CLOSED) {
        socket.close();
      }
    });
    socket.onclose = (e) => {
      debug8("msl:websocket:close")(`${e.code}`);
      if (e.code === CLOSE_GOING_AWAY) {
        this.onServerClose && this.onServerClose();
      }
      incoming.push(null);
      outgoing.end();
    };
    super(incoming, outgoing);
    __publicField(this, "onServerClose");
  }
  /**
   * Expose websocket opener as a class method that returns a promise which
   * resolves with a new WebSocketComponent.
   */
  static open(config) {
    return __async(this, null, function* () {
      return yield openWebSocket(config).then((socket) => new _WSSource(socket));
    });
  }
};

// src/pipelines/index.browser.ts
var index_browser_exports2 = {};
__export(index_browser_exports2, {
  Html5CanvasPipeline: () => Html5CanvasPipeline,
  Html5VideoMetadataPipeline: () => Html5VideoMetadataPipeline,
  Html5VideoPipeline: () => Html5VideoPipeline,
  HttpMsePipeline: () => HttpMsePipeline,
  MetadataPipeline: () => MetadataPipeline,
  Pipeline: () => Pipeline,
  RtspMjpegPipeline: () => RtspMjpegPipeline,
  RtspMp4Pipeline: () => RtspMp4Pipeline,
  RtspPipeline: () => RtspPipeline,
  WsSdpPipeline: () => WsSdpPipeline
});

// src/pipelines/pipeline.ts
var Pipeline = class {
  /**
   * @param components - The components of the pipeline in order.
   */
  constructor(...components) {
    __publicField(this, "firstComponent");
    __publicField(this, "lastComponent");
    __publicField(this, "_set");
    const [car, ...cdr] = components;
    this._set = new Set(components);
    this.firstComponent = car;
    this.lastComponent = cdr.reduce((last, component) => {
      return last.connect(component);
    }, car);
  }
  /**
   * @param components - The components of the pipeline in order.
   */
  init(...components) {
    const [car, ...cdr] = components;
    this._set = new Set(components);
    this.firstComponent = car;
    this.lastComponent = cdr.reduce((last, component) => {
      return last.connect(component);
    }, car);
  }
  /**
   * Inserts a component into the pipeline.
   *
   * @param component - Tube or Source behind which to insert a new component.
   * @param component - Tube or Sink to insert.
   */
  insertAfter(component, newComponent) {
    if (!this._set.has(component)) {
      throw new Error("insertion point not part of pipeline");
    }
    if (this._set.has(newComponent)) {
      throw new Error("new component already in the pipeline");
    }
    const cdr = component.next;
    if (cdr === null) {
      component.connect(newComponent);
      this.lastComponent = newComponent;
    } else {
      component.disconnect();
      component.connect(newComponent).connect(cdr);
    }
    this._set.add(newComponent);
    return this;
  }
  /**
   * Inserts a component into the pipeline.
   *
   * @param component - Tube or Sink in front of which to insert a new component.
   * @param component - Tube or Source to insert.
   */
  insertBefore(component, newComponent) {
    if (!this._set.has(component)) {
      throw new Error("insertion point not part of pipeline");
    }
    if (this._set.has(newComponent)) {
      throw new Error("new component already in the pipeline");
    }
    const car = component.prev;
    if (car === null) {
      newComponent.connect(component);
      this.firstComponent = newComponent;
    } else {
      car.disconnect();
      car.connect(newComponent).connect(component);
    }
    this._set.add(newComponent);
    return this;
  }
  /**
   * Removes a component from the pipeline.
   *
   * @param component - Component to remove.
   */
  remove(component) {
    if (!this._set.has(component)) {
      throw new Error("component not part of pipeline");
    }
    const car = component.prev;
    const cdr = component.next;
    if (car === null && cdr === null) {
      throw new Error("cannot remove last component");
    } else if (car === null && cdr !== null) {
      component.disconnect();
      this.firstComponent = cdr;
    } else if (car !== null && cdr === null) {
      car.disconnect();
      this.lastComponent = car;
    } else if (car !== null && cdr !== null) {
      car.disconnect();
      const cmp = component;
      cmp.disconnect();
      car.connect(cdr);
    }
    this._set.delete(component);
    return this;
  }
  /**
   * Inserts a component at the end of the pipeline.
   *
   * @param component - Tube or Sink to insert.
   */
  append(...components) {
    components.forEach((component) => {
      this.insertAfter(this.lastComponent, component);
    });
    return this;
  }
  /**
   * Inserts a component at the beginning of the pipeline.
   *
   * @param component - Tube or Source to insert.
   */
  prepend(...components) {
    components.forEach((component) => {
      this.insertBefore(this.firstComponent, component);
    });
    return this;
  }
};

// src/pipelines/rtsp-pipeline.ts
var RtspPipeline = class extends Pipeline {
  constructor(rtspConfig) {
    const rtspParser = new RtspParser();
    const rtspSession = new RtspSession(rtspConfig);
    rtspSession.onSdp = (sdp) => {
      this.onSdp && this.onSdp(sdp);
    };
    rtspSession.onPlay = (range2) => {
      this.onPlay && this.onPlay(range2);
    };
    super(rtspParser, rtspSession);
    __publicField(this, "onSdp");
    __publicField(this, "onPlay");
    __publicField(this, "rtsp");
    this.rtsp = rtspSession;
  }
};

// src/pipelines/rtsp-mjpeg-pipeline.ts
var RtspMjpegPipeline = class extends RtspPipeline {
  constructor(rtspConfig) {
    super(rtspConfig);
    const jpegDepay = new JPEGDepay();
    this.append(jpegDepay);
  }
};

// src/pipelines/rtsp-mp4-pipeline.ts
var RtspMp4Pipeline = class extends RtspPipeline {
  constructor(rtspConfig) {
    super(rtspConfig);
    __publicField(this, "onSync");
    __publicField(this, "_mp4Muxer");
    const h264Depay = new H264Depay();
    const aacDepay = new AACDepay();
    const mp4Muxer = new Mp4Muxer();
    mp4Muxer.onSync = (ntpPresentationTime) => {
      this.onSync && this.onSync(ntpPresentationTime);
    };
    this.append(h264Depay, aacDepay, mp4Muxer);
    this._mp4Muxer = mp4Muxer;
  }
  get bitrate() {
    return this._mp4Muxer.bitrate;
  }
  get framerate() {
    return this._mp4Muxer.framerate;
  }
};

// src/components/auth/digest.ts
import { Md5 as MD5 } from "ts-md5";
function md5Hash(s) {
  const hash = new MD5().appendStr(s).end();
  if (hash === void 0) {
    throw new Error("empty MD5 hash");
  }
  return hash.toString();
}
var DigestAuth = class {
  constructor(params, username, password) {
    __publicField(this, "realm");
    __publicField(this, "nonce");
    __publicField(this, "opaque");
    __publicField(this, "algorithm");
    __publicField(this, "qop");
    __publicField(this, "username");
    __publicField(this, "ha1Base");
    __publicField(this, "count");
    __publicField(this, "nc", () => {
      ;
      ++this.count;
      return this.count.toString(16).padStart(8, "0");
    });
    __publicField(this, "cnonce", () => {
      return new Array(4).fill(0).map(() => Math.floor(Math.random() * 256)).map((n) => n.toString(16)).join("");
    });
    __publicField(this, "ha1", (cnonce) => {
      let ha1 = this.ha1Base;
      if (this.algorithm === "md5-sess") {
        ha1 = md5Hash(`${ha1}:${this.nonce}:${cnonce}`);
      }
      return ha1;
    });
    __publicField(this, "ha2", (method, uri, body = "") => {
      let ha2 = md5Hash(`${method}:${uri}`);
      if (this.algorithm === "md5-sess") {
        const hbody = md5Hash(body);
        ha2 = md5Hash(`${method}:${uri}:${hbody}`);
      }
      return ha2;
    });
    __publicField(this, "authorization", (method = "GET", uri = "", body) => {
      const nc = this.nc();
      const cnonce = this.cnonce();
      const ha1 = this.ha1(cnonce);
      const ha2 = this.ha2(method, uri, body);
      const response = this.qop === void 0 ? md5Hash(`${ha1}:${this.nonce}:${ha2}`) : md5Hash(`${ha1}:${this.nonce}:${nc}:${cnonce}:${this.qop}:${ha2}`);
      const authorizationParams = [];
      authorizationParams.push(`username="${this.username}"`);
      authorizationParams.push(`realm="${this.realm}"`);
      authorizationParams.push(`nonce="${this.nonce}"`);
      authorizationParams.push(`uri="${uri}"`);
      if (this.qop !== void 0) {
        authorizationParams.push(`qop=${this.qop}`);
        authorizationParams.push(`nc=${nc}`);
        authorizationParams.push(`cnonce="${cnonce}"`);
      }
      authorizationParams.push(`response="${response}"`);
      if (this.opaque !== void 0) {
        authorizationParams.push(`opaque="${this.opaque}"`);
      }
      return `Digest ${authorizationParams.join(", ")}`;
    });
    const realm = params.get("realm");
    if (realm === void 0) {
      throw new Error("no realm in digest challenge");
    }
    this.realm = realm;
    this.ha1Base = md5Hash(`${username}:${realm}:${password}`);
    const nonce = params.get("nonce");
    if (nonce === void 0) {
      throw new Error("no nonce in digest challenge");
    }
    this.nonce = nonce;
    this.opaque = params.get("opaque");
    const algorithm = params.get("algorithm");
    if (algorithm !== void 0) {
      if (algorithm === "md5") {
        this.algorithm = "md5";
      } else if (algorithm === "md5-sess") {
        this.algorithm = "md5-sess";
      }
    } else {
      this.algorithm = "md5";
    }
    const qop = params.get("qop");
    if (qop !== void 0) {
      const possibleQops = qop.split(",").map((qopType) => qopType.trim());
      if (possibleQops.some((qopValue) => qopValue === "auth")) {
        this.qop = "auth";
      } else if (possibleQops.some((qopValue) => qopValue === "auth-int")) {
        this.qop = "auth-int";
      }
    }
    this.count = 0;
    this.username = username;
  }
};

// src/components/auth/www-authenticate.ts
var parseWWWAuthenticate = (header) => {
  const [, type, ...challenge] = header.split(" ");
  const pairs = [];
  const re = /\s*([^=]+)="([^"]*)",?/gm;
  let match;
  do {
    match = re.exec(challenge.join(" "));
    if (match !== null) {
      const [, key, value] = match;
      pairs.push([key, value]);
    }
  } while (match !== null);
  const params = new Map(pairs);
  return { type: type.toLowerCase(), params };
};

// src/components/auth/index.ts
var UNAUTHORIZED = 401;
var DEFAULT_CONFIG = {
  username: "root",
  password: "pass"
};
var Auth = class extends Tube {
  constructor(config = {}) {
    const { username, password } = merge(DEFAULT_CONFIG, config);
    if (username === void 0 || password === void 0) {
      throw new Error("need username and password");
    }
    let lastSentMessage;
    let authHeader;
    const outgoing = createTransform(function(msg, encoding, callback) {
      if (msg.type === 4 /* RTSP */) {
        lastSentMessage = msg;
        if (authHeader && msg.headers) {
          msg.headers.Authorization = authHeader;
        }
      }
      callback(void 0, msg);
    });
    const incoming = createTransform(function(msg, encoding, callback) {
      if (msg.type === 4 /* RTSP */ && statusCode(msg.data) === UNAUTHORIZED) {
        const headers = msg.data.toString().split("\n");
        const wwwAuth = headers.find((header) => /WWW-Auth/i.test(header));
        if (wwwAuth === void 0) {
          throw new Error("cannot find WWW-Authenticate header");
        }
        const challenge = parseWWWAuthenticate(wwwAuth);
        if (challenge.type === "basic") {
          authHeader = `Basic ${Buffer.from(`${username}:${password}`).toString(
            "base64"
          )}`;
        } else if (challenge.type === "digest") {
          const digest = new DigestAuth(challenge.params, username, password);
          authHeader = digest.authorization(
            lastSentMessage.method,
            lastSentMessage.uri
          );
        } else {
          return;
        }
        outgoing.write(lastSentMessage, () => callback());
      } else {
        callback(void 0, msg);
      }
    });
    super(incoming, outgoing);
  }
};

// src/pipelines/html5-canvas-pipeline.ts
var Html5CanvasPipeline = class extends RtspMjpegPipeline {
  constructor(config) {
    const {
      ws: wsConfig,
      rtsp: rtspConfig,
      mediaElement,
      auth: authConfig
    } = config;
    super(rtspConfig);
    __publicField(this, "onCanplay");
    __publicField(this, "onSync");
    __publicField(this, "onServerClose");
    __publicField(this, "ready");
    __publicField(this, "_src");
    __publicField(this, "_sink");
    if (authConfig) {
      const auth = new Auth(authConfig);
      this.insertBefore(this.rtsp, auth);
    }
    const canvasSink = new CanvasSink(mediaElement);
    canvasSink.onCanplay = () => {
      canvasSink.play();
      this.onCanplay && this.onCanplay();
    };
    canvasSink.onSync = (ntpPresentationTime) => {
      this.onSync && this.onSync(ntpPresentationTime);
    };
    this.append(canvasSink);
    this._sink = canvasSink;
    const waitForWs = WSSource.open(wsConfig);
    this.ready = waitForWs.then((wsSource) => {
      wsSource.onServerClose = () => {
        this.onServerClose && this.onServerClose();
      };
      this.prepend(wsSource);
      this._src = wsSource;
    });
  }
  close() {
    this.rtsp.stop();
    this._src && this._src.outgoing.end();
  }
  get currentTime() {
    return this._sink.currentTime;
  }
  play() {
    return this._sink.play();
  }
  pause() {
    return this._sink.pause();
  }
  get bitrate() {
    return this._sink.bitrate;
  }
  get framerate() {
    return this._sink.framerate;
  }
};

// src/pipelines/html5-video-pipeline.ts
var Html5VideoPipeline = class extends RtspMp4Pipeline {
  constructor(config) {
    const {
      ws: wsConfig,
      rtsp: rtspConfig,
      mediaElement,
      auth: authConfig
    } = config;
    super(rtspConfig);
    __publicField(this, "onSourceOpen");
    __publicField(this, "onServerClose");
    __publicField(this, "ready");
    __publicField(this, "tracks");
    __publicField(this, "_src");
    __publicField(this, "_sink");
    if (authConfig) {
      const auth = new Auth(authConfig);
      this.insertBefore(this.rtsp, auth);
    }
    const mseSink = new MseSink(mediaElement);
    mseSink.onSourceOpen = (mse, tracks) => {
      this.tracks = tracks;
      this.onSourceOpen && this.onSourceOpen(mse, tracks);
    };
    this.append(mseSink);
    this._sink = mseSink;
    const waitForWs = WSSource.open(wsConfig);
    this.ready = waitForWs.then((wsSource) => {
      wsSource.onServerClose = () => {
        this.onServerClose && this.onServerClose();
      };
      this.prepend(wsSource);
      this._src = wsSource;
    });
  }
  close() {
    this.rtsp.stop();
    this._src && this._src.outgoing.end();
  }
  get currentTime() {
    return this._sink.currentTime;
  }
  play() {
    return __async(this, null, function* () {
      return yield this._sink.play();
    });
  }
  pause() {
    return this._sink.pause();
  }
};

// src/pipelines/html5-video-metadata-pipeline.ts
var Html5VideoMetadataPipeline = class extends Html5VideoPipeline {
  constructor(config) {
    const { metadataHandler } = config;
    super(config);
    const onvifDepay = new ONVIFDepay();
    this.insertAfter(this.rtsp, onvifDepay);
    const onvifHandlerPipe = Tube.fromHandlers((msg) => {
      if (msg.type === 9 /* XML */) {
        metadataHandler(msg);
      }
    }, void 0);
    this.insertAfter(onvifDepay, onvifHandlerPipe);
  }
};

// src/pipelines/metadata-pipeline.ts
var DEFAULT_RTSP_PARAMETERS = {
  parameters: ["audio=0", "video=0", "event=on", "ptz=all"]
};
var MetadataPipeline = class extends RtspPipeline {
  constructor(config) {
    const { ws: wsConfig, rtsp: rtspConfig, metadataHandler } = config;
    super(Object.assign({}, DEFAULT_RTSP_PARAMETERS, rtspConfig));
    __publicField(this, "onServerClose");
    __publicField(this, "ready");
    __publicField(this, "_src");
    const onvifDepay = new ONVIFDepay();
    this.append(onvifDepay);
    const handlerSink = Sink.fromHandler((msg) => {
      if (msg.type === 9 /* XML */) {
        metadataHandler(msg);
      }
    });
    this.append(handlerSink);
    const waitForWs = WSSource.open(wsConfig);
    this.ready = waitForWs.then((wsSource) => {
      wsSource.onServerClose = () => {
        this.onServerClose && this.onServerClose();
      };
      this.prepend(wsSource);
      this._src = wsSource;
    });
  }
  close() {
    this._src && this._src.outgoing.end();
  }
};

// src/pipelines/ws-sdp-pipeline.ts
var WsSdpPipeline = class extends RtspPipeline {
  constructor(config) {
    const { ws: wsConfig, rtsp: rtspConfig, auth: authConfig } = config;
    super(rtspConfig);
    __publicField(this, "onServerClose");
    __publicField(this, "ready");
    __publicField(this, "_src");
    if (authConfig) {
      const auth = new Auth(authConfig);
      this.insertBefore(this.rtsp, auth);
    }
    const waitForWs = WSSource.open(wsConfig);
    this.ready = waitForWs.then((wsSource) => {
      wsSource.onServerClose = () => {
        this.onServerClose && this.onServerClose();
      };
      this.prepend(wsSource);
      this._src = wsSource;
    });
  }
  close() {
    this._src && this._src.outgoing.end();
  }
  get sdp() {
    return this.ready.then(() => __async(this, null, function* () {
      const sdpPromise = new Promise((resolve) => {
        this.rtsp.onSdp = resolve;
      });
      this.rtsp.send({ method: "DESCRIBE" /* DESCRIBE */ });
      this.rtsp.send({ method: "TEARDOWN" /* TEARDOWN */ });
      return yield sdpPromise;
    }));
  }
};

// src/components/http-mp4/index.ts
import registerDebug3 from "debug";
import { Readable as Readable7 } from "stream";
var debug9 = registerDebug3("msl:http-mp4");
var HttpMp4Source = class extends Source {
  /**
   * Create an HTTP component.
   *
   * The constructor sets a single readable stream from a fetch.
   */
  constructor(config) {
    const { uri, options } = config;
    const incoming = new Readable7({
      objectMode: true,
      read() {
      }
    });
    incoming.on("error", (e) => {
      console.warn("closing socket due to incoming error", e);
      this._reader && this._reader.cancel().catch((err) => console.error(err));
    });
    super(incoming);
    __publicField(this, "uri");
    __publicField(this, "options");
    __publicField(this, "length");
    __publicField(this, "onHeaders");
    __publicField(this, "onServerClose");
    __publicField(this, "_reader");
    __publicField(this, "_abortController");
    __publicField(this, "_allDone");
    incoming._read = () => {
      this._pull();
    };
    this.uri = uri;
    this.options = options;
    this._allDone = false;
  }
  play() {
    if (this.uri === void 0) {
      throw new Error("cannot start playing when there is no URI");
    }
    this._abortController = new AbortController();
    this.length = 0;
    fetch(this.uri, __spreadValues({
      credentials: "include",
      signal: this._abortController.signal
    }, this.options)).then((rsp) => {
      if (rsp.body === null) {
        throw new Error("empty response body");
      }
      const contentType = rsp.headers.get("Content-Type");
      this.incoming.push({
        data: Buffer.alloc(0),
        type: 8 /* ISOM */,
        mime: contentType
      });
      this.onHeaders && this.onHeaders(rsp.headers);
      this._reader = rsp.body.getReader();
      this._pull();
    }).catch((err) => {
      console.error("http-source: fetch failed: ", err);
    });
  }
  abort() {
    this._reader && this._reader.cancel().catch((err) => {
      console.log("http-source: cancel reader failed: ", err);
    });
    this._abortController && this._abortController.abort();
  }
  _isClosed() {
    return this._allDone;
  }
  _close() {
    var _a;
    this._reader = void 0;
    this._allDone = true;
    this.incoming.push(null);
    (_a = this.onServerClose) == null ? void 0 : _a.call(this);
  }
  _pull() {
    if (this._reader === void 0) {
      return;
    }
    this._reader.read().then(({ done, value }) => {
      if (done) {
        if (!this._isClosed()) {
          debug9("fetch completed, total downloaded: ", this.length, " bytes");
          this._close();
        }
        return;
      }
      if (value === void 0) {
        throw new Error("expected value to be defined");
      }
      if (this.length === void 0) {
        throw new Error("expected length to be defined");
      }
      this.length += value.length;
      const buffer = Buffer.from(value);
      if (!this.incoming.push({ data: buffer, type: 8 /* ISOM */ })) {
        debug9("downstream back pressure: pausing read");
      } else {
        this._pull();
      }
    }).catch((err) => {
      debug9("http-source: read failed: ", err);
      if (!this._isClosed()) {
        this._close();
      }
    });
  }
};

// src/pipelines/http-mse-pipeline.ts
var HttpMsePipeline = class extends Pipeline {
  constructor(config) {
    const { http: httpConfig, mediaElement } = config;
    const httpSource = new HttpMp4Source(httpConfig);
    const mseSink = new MseSink(mediaElement);
    httpSource.onHeaders = (headers) => {
      this.onHeaders && this.onHeaders(headers);
    };
    httpSource.onServerClose = () => {
      var _a;
      return (_a = this.onServerClose) == null ? void 0 : _a.call(this);
    };
    super(httpSource, mseSink);
    __publicField(this, "onHeaders");
    __publicField(this, "onServerClose");
    __publicField(this, "http");
    __publicField(this, "_src");
    __publicField(this, "_sink");
    this._src = httpSource;
    this._sink = mseSink;
    this.http = httpSource;
  }
  close() {
    this._src && this._src.abort();
  }
  get currentTime() {
    return this._sink.currentTime;
  }
  play() {
    return __async(this, null, function* () {
      return yield this._sink.play();
    });
  }
  pause() {
    return this._sink.pause();
  }
};

// src/utils/index.browser.ts
var index_browser_exports3 = {};
__export(index_browser_exports3, {
  RTCPPacketType: () => RTCPPacketType,
  SDESItem: () => SDESItem,
  SR: () => SR,
  Scheduler: () => Scheduler,
  addRTSPRetry: () => addRTSPRetry,
  bodyOffset: () => bodyOffset,
  cSrc: () => cSrc,
  cSrcCount: () => cSrcCount,
  connectionEnded: () => connectionEnded,
  contentBase: () => contentBase,
  contentLocation: () => contentLocation,
  extHeader: () => extHeader,
  extHeaderLength: () => extHeaderLength,
  extension: () => extension,
  extractHeaderValue: () => extractHeaderValue,
  extractURIs: () => extractURIs,
  getTime: () => getTime,
  isRtcpApp: () => isRtcpApp,
  isRtcpBye: () => isRtcpBye,
  isRtcpRR: () => isRtcpRR,
  isRtcpSDES: () => isRtcpSDES,
  isRtcpSR: () => isRtcpSR,
  marker: () => marker,
  messageFromBuffer: () => messageFromBuffer,
  padding: () => padding,
  parse: () => parse2,
  parseRtcp: () => parseRtcp,
  payload: () => payload,
  payloadType: () => payloadType,
  range: () => range,
  rtcpMessageFromBuffer: () => rtcpMessageFromBuffer,
  sSrc: () => sSrc,
  sequence: () => sequence,
  sequenceNumber: () => sequenceNumber,
  sessionId: () => sessionId,
  sessionTimeout: () => sessionTimeout,
  statusCode: () => statusCode,
  timestamp: () => timestamp,
  version: () => version
});

// src/utils/retry.ts
var addRTSPRetry = (rtspSession, { maxRetries, errors } = { maxRetries: 20, errors: [503] }) => {
  let retries = 0;
  const oldOnError = rtspSession.onError;
  rtspSession.onError = (err) => {
    oldOnError == null ? void 0 : oldOnError(err);
    if (!errors.includes(err.code)) {
      return;
    }
    if ((retries += 1) > maxRetries) {
      console.log("retry, too many", retries, maxRetries);
      return;
    }
    setTimeout(() => {
      var _a;
      return (_a = rtspSession.retry) == null ? void 0 : _a.call(rtspSession);
    }, retries * 100);
  };
};
export {
  AACDepay,
  BasicDepay,
  CanvasSink,
  H264Depay,
  Html5CanvasPipeline,
  Html5VideoMetadataPipeline,
  Html5VideoPipeline,
  HttpMsePipeline,
  HttpSource,
  Inspector,
  JPEGDepay,
  MessageType,
  MetadataPipeline,
  Mp4Capture,
  Mp4Muxer,
  MseSink,
  ONVIFDepay,
  Pipeline,
  RTCPPacketType,
  RTSPResponseError,
  RTSP_METHOD,
  RtspMjpegPipeline,
  RtspMp4Pipeline,
  RtspParser,
  RtspPipeline,
  RtspSession,
  SDESItem,
  SR,
  Scheduler,
  Sink,
  Source,
  Tube,
  WSSource,
  WsSdpPipeline,
  addRTSPRetry,
  bodyOffset,
  cSrc,
  cSrcCount,
  index_browser_exports as components,
  connectionEnded,
  contentBase,
  contentLocation,
  createTransform,
  extHeader,
  extHeaderLength,
  extension,
  extractHeaderValue,
  extractURIs,
  getTime,
  isRtcpApp,
  isRtcpBye,
  isRtcpRR,
  isRtcpSDES,
  isRtcpSR,
  marker,
  messageFromBuffer,
  padding,
  parse2 as parse,
  parseRtcp,
  payload,
  payloadType,
  index_browser_exports2 as pipelines,
  range,
  rtcpMessageFromBuffer,
  sSrc,
  sequence,
  sequenceNumber,
  sessionId,
  sessionTimeout,
  statusCode,
  timestamp,
  index_browser_exports3 as utils,
  version
};
//# sourceMappingURL=browser-light-esm.js.map
